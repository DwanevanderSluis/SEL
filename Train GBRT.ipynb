{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from sklearn.ensemble import GradientBoostingRegressor \n",
    "from sellibrary.gbrt import GBRTWrapper\n",
    "from sellibrary.text_file_loader import load_feature_matrix\n",
    "from sellibrary.filter_only_golden import FilterGolden\n",
    "from sellibrary.locations import FileLocations\n",
    "from sellibrary.wiki.wikipedia_datasets import WikipediaDataset\n",
    "from sellibrary.sel.dexter_dataset import DatasetDexter\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "\n",
    "INTERMEDIATE_PATH = FileLocations.get_dropbox_intermediate_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup logging\n",
    "\n",
    "\n",
    "handler = logging.StreamHandler()\n",
    "handler.setFormatter(logging.Formatter('%(asctime)s %(name)-12s %(levelname)-8s %(message)s'))\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.addHandler(handler)\n",
    "logger.propagate = False\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "    'v1_graph_size', 'v1_graph_diameter', 'v1_node_degree', 'v1_degree_mean_median_ratio',\n",
    "    'v1_out_degree_mean_median_ratio', 'v1_degree_mean_median_ratio', 'v1_farness', 'v1_closeness', 'v1_centrality',\n",
    "    'v1_minus_low_relatedness_graph_size', 'v1_minus_low_relatedness_graph_diameter',\n",
    "    'v1_minus_low_relatedness_node_degree', 'v1_minus_low_relatedness_degree_mean_median_ratio',\n",
    "    'v1_minus_low_relatedness_out_degree_mean_median_ratio', 'v1_minus_low_relatedness_degree_mean_median_ratio',\n",
    "    'v1_minus_low_relatedness_farness', 'v1_minus_low_relatedness_closeness',\n",
    "    'v1_minus_low_relatedness_centrality','v0_graph_size', 'v0_graph_diameter', 'v0_node_degree',\n",
    "    'v0_degree_mean_median_ratio', 'v0_out_degree_mean_median_ratio', 'v0_degree_mean_median_ratio', 'v0_farness',\n",
    "    'v0_closeness', 'v0_centrality', 'v0_minus_low_relatedness_graph_size',\n",
    "    'v0_minus_low_relatedness_graph_diameter', 'v0_minus_low_relatedness_node_degree',\n",
    "    'v0_minus_low_relatedness_degree_mean_median_ratio', 'v0_minus_low_relatedness_out_degree_mean_median_ratio',\n",
    "    'v0_minus_low_relatedness_degree_mean_median_ratio', 'v0_minus_low_relatedness_farness',\n",
    "    'v0_minus_low_relatedness_closeness', 'v0_minus_low_relatedness_centrality'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-11 10:41:22,467 sellibrary.text_file_loader INFO     loading data from : /project/Dropbox/Datasets/intermediate/dexter_all_heavy_catted_8_7_2018.txt\n",
      "2018-07-11 10:41:22,703 sellibrary.text_file_loader INFO     skipping line with 1 rather than 40 fields \"\"\n",
      "2018-07-11 10:41:22,704 sellibrary.text_file_loader INFO     0 lines processed\n",
      "2018-07-11 10:41:22,705 sellibrary.text_file_loader INFO     skipping line with 5 rather than 40 fields \"docId, entity_id, golden_salience, estimated_salience, [heavy_features]\"\n",
      "2018-07-11 10:41:22,706 sellibrary.text_file_loader INFO     0 lines processed\n",
      "2018-07-11 10:41:22,745 sellibrary.text_file_loader INFO     10000 lines processed\n",
      "2018-07-11 10:41:22,784 sellibrary.text_file_loader INFO     20000 lines processed\n",
      "2018-07-11 10:41:22,823 sellibrary.text_file_loader INFO     30000 lines processed\n",
      "2018-07-11 10:41:22,860 sellibrary.text_file_loader INFO     40000 lines processed\n",
      "2018-07-11 10:41:22,873 sellibrary.text_file_loader INFO     skipping line with 1 rather than 40 fields \"\"\n",
      "2018-07-11 10:41:22,873 sellibrary.text_file_loader INFO     skipping line with 5 rather than 40 fields \"docId, entity_id, golden_salience, estimated_salience, [heavy_features]\"\n",
      "2018-07-11 10:41:22,874 sellibrary.text_file_loader INFO     skipping line with 1 rather than 40 fields \"\"\n",
      "2018-07-11 10:41:22,875 sellibrary.text_file_loader INFO     skipping line with 5 rather than 40 fields \"docId, entity_id, golden_salience, estimated_salience, [heavy_features]\"\n",
      "2018-07-11 10:41:22,901 sellibrary.text_file_loader INFO     50000 lines processed\n",
      "2018-07-11 10:41:22,938 sellibrary.text_file_loader INFO     60000 lines processed\n",
      "2018-07-11 10:41:22,975 sellibrary.text_file_loader INFO     70000 lines processed\n",
      "2018-07-11 10:41:23,000 sellibrary.text_file_loader INFO     skipping line with 1 rather than 40 fields \"\"\n",
      "2018-07-11 10:41:23,001 sellibrary.text_file_loader INFO     skipping line with 5 rather than 40 fields \"docId, entity_id, golden_salience, estimated_salience, [heavy_features]\"\n",
      "2018-07-11 10:41:23,014 sellibrary.text_file_loader INFO     80000 lines processed\n",
      "2018-07-11 10:41:23,018 sellibrary.text_file_loader INFO     skipping line with 1 rather than 40 fields \"\"\n",
      "2018-07-11 10:41:23,018 sellibrary.text_file_loader INFO     skipping line with 5 rather than 40 fields \"docId, entity_id, golden_salience, estimated_salience, [heavy_features]\"\n",
      "2018-07-11 10:41:23,053 sellibrary.text_file_loader INFO     90000 lines processed\n",
      "2018-07-11 10:41:23,091 sellibrary.text_file_loader INFO     100000 lines processed\n",
      "2018-07-11 10:41:23,129 sellibrary.text_file_loader INFO     110000 lines processed\n",
      "2018-07-11 10:41:23,165 sellibrary.text_file_loader INFO     120000 lines processed\n",
      "2018-07-11 10:41:23,194 sellibrary.text_file_loader INFO     skipping line with 1 rather than 40 fields \"\"\n",
      "2018-07-11 10:41:23,194 sellibrary.text_file_loader INFO     skipping line with 5 rather than 40 fields \"docId, entity_id, golden_salience, estimated_salience, [heavy_features]\"\n",
      "2018-07-11 10:41:23,206 sellibrary.text_file_loader INFO     130000 lines processed\n",
      "2018-07-11 10:41:23,243 sellibrary.text_file_loader INFO     140000 lines processed\n",
      "2018-07-11 10:41:23,282 sellibrary.text_file_loader INFO     150000 lines processed\n",
      "2018-07-11 10:41:23,320 sellibrary.text_file_loader INFO     160000 lines processed\n",
      "2018-07-11 10:41:23,341 sellibrary.text_file_loader INFO     skipping line with 1 rather than 40 fields \"\"\n",
      "2018-07-11 10:41:23,341 sellibrary.text_file_loader INFO     skipping line with 5 rather than 40 fields \"docId, entity_id, golden_salience, estimated_salience, [heavy_features]\"\n",
      "2018-07-11 10:41:23,360 sellibrary.text_file_loader INFO     170000 lines processed\n",
      "2018-07-11 10:41:23,363 sellibrary.text_file_loader INFO     skipping line with 1 rather than 40 fields \"\"\n",
      "2018-07-11 10:41:23,363 sellibrary.text_file_loader INFO     skipping line with 5 rather than 40 fields \"docId, entity_id, golden_salience, estimated_salience, [heavy_features]\"\n",
      "2018-07-11 10:41:23,364 sellibrary.text_file_loader INFO     skipping line with 1 rather than 40 fields \"\"\n",
      "2018-07-11 10:41:23,364 sellibrary.text_file_loader INFO     skipping line with 5 rather than 40 fields \"docId, entity_id, golden_salience, estimated_salience, [heavy_features]\"\n",
      "2018-07-11 10:41:23,401 sellibrary.text_file_loader INFO     180000 lines processed\n",
      "2018-07-11 10:41:23,439 sellibrary.text_file_loader INFO     190000 lines processed\n",
      "2018-07-11 10:41:23,476 sellibrary.text_file_loader INFO     200000 lines processed\n",
      "2018-07-11 10:41:23,513 sellibrary.text_file_loader INFO     210000 lines processed\n",
      "2018-07-11 10:41:23,526 sellibrary.text_file_loader INFO     skipping line with 1 rather than 40 fields \"\"\n",
      "2018-07-11 10:41:23,527 sellibrary.text_file_loader INFO     skipping line with 5 rather than 40 fields \"docId, entity_id, golden_salience, estimated_salience, [heavy_features]\"\n",
      "2018-07-11 10:41:23,531 sellibrary.text_file_loader INFO     skipping line with 1 rather than 40 fields \"\"\n",
      "2018-07-11 10:41:23,531 sellibrary.text_file_loader INFO     skipping line with 5 rather than 40 fields \"docId, entity_id, golden_salience, estimated_salience, [heavy_features]\"\n",
      "2018-07-11 10:41:23,555 sellibrary.text_file_loader INFO     220000 lines processed\n",
      "2018-07-11 10:41:23,592 sellibrary.text_file_loader INFO     230000 lines processed\n",
      "2018-07-11 10:41:23,629 sellibrary.text_file_loader INFO     240000 lines processed\n",
      "2018-07-11 10:41:23,634 sellibrary.text_file_loader INFO     241271 lines loaded from /project/Dropbox/Datasets/intermediate/dexter_all_heavy_catted_8_7_2018.txt\n",
      "2018-07-11 10:41:34,498 __main__     INFO     X Shape = (241271, 36)\n",
      "2018-07-11 10:41:34,500 __main__     INFO     y Shape = (241271,)\n",
      "2018-07-11 10:41:34,511 sellibrary.wiki.wikipedia_datasets INFO     Loading /project/Dropbox/Datasets/wikipedia/wikititle_id_by_id.case_insensitive.15910478.pickle\n",
      "2018-07-11 10:41:53,481 sellibrary.wiki.wikipedia_datasets INFO     Loaded /project/Dropbox/Datasets/wikipedia/wikititle_id_by_id.case_insensitive.15910478.pickle\n",
      "2018-07-11 10:41:53,791 sellibrary.gbrt INFO     GBC trees: <sklearn.tree._tree.Tree object at 0x7f7a5522b100>\n",
      "2018-07-11 10:41:53,793 sellibrary.gbrt INFO     GBC trees: <sklearn.tree._tree.Tree object at 0x7f7a55512a58>\n",
      "2018-07-11 10:41:53,794 sellibrary.gbrt INFO     GBC trees: <sklearn.tree._tree.Tree object at 0x7f7a55512b28>\n",
      "2018-07-11 10:41:53,795 sellibrary.gbrt INFO     GBC trees: <sklearn.tree._tree.Tree object at 0x7f7a555124a8>\n",
      "2018-07-11 10:41:53,796 sellibrary.gbrt INFO     GBC trees: <sklearn.tree._tree.Tree object at 0x7f7a55512d30>\n",
      "2018-07-11 10:41:53,797 sellibrary.gbrt INFO     GBC trees: <sklearn.tree._tree.Tree object at 0x7f7a5057d030>\n",
      "2018-07-11 10:41:53,798 sellibrary.gbrt INFO     GBC trees: <sklearn.tree._tree.Tree object at 0x7f7a74bc0ed0>\n",
      "2018-07-11 10:41:53,799 sellibrary.gbrt INFO     GBC trees: <sklearn.tree._tree.Tree object at 0x7f7a74bc0e68>\n",
      "2018-07-11 10:41:53,800 sellibrary.gbrt INFO     GBC trees: <sklearn.tree._tree.Tree object at 0x7f7a5525eed0>\n",
      "2018-07-11 10:41:53,802 sellibrary.gbrt INFO     GBC trees: <sklearn.tree._tree.Tree object at 0x7f7a5525ee68>\n",
      "2018-07-11 10:41:53,803 sellibrary.gbrt INFO     GBC trees: <sklearn.tree._tree.Tree object at 0x7f7a5525ef38>\n",
      "2018-07-11 10:41:53,804 sellibrary.gbrt INFO     GBC trees: <sklearn.tree._tree.Tree object at 0x7f79c29c8030>\n",
      "2018-07-11 10:41:53,805 sellibrary.gbrt INFO     GBC trees: <sklearn.tree._tree.Tree object at 0x7f79c29c8098>\n",
      "2018-07-11 10:41:53,807 sellibrary.gbrt INFO     GBC trees: <sklearn.tree._tree.Tree object at 0x7f79c29c8100>\n",
      "2018-07-11 10:41:53,808 sellibrary.gbrt INFO     GBC trees: <sklearn.tree._tree.Tree object at 0x7f79c29c8168>\n",
      "2018-07-11 10:41:53,809 sellibrary.gbrt INFO     GBC trees: <sklearn.tree._tree.Tree object at 0x7f79c29c81d0>\n",
      "2018-07-11 10:41:53,810 sellibrary.gbrt INFO     GBC trees: <sklearn.tree._tree.Tree object at 0x7f79c29c8238>\n",
      "2018-07-11 10:41:53,811 sellibrary.gbrt INFO     GBC trees: <sklearn.tree._tree.Tree object at 0x7f79c29c82a0>\n",
      "2018-07-11 10:41:53,812 sellibrary.gbrt INFO     GBC trees: <sklearn.tree._tree.Tree object at 0x7f79c29c8308>\n",
      "2018-07-11 10:41:53,813 sellibrary.gbrt INFO     GBC trees: <sklearn.tree._tree.Tree object at 0x7f79c29c8370>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-11 10:41:53,814 sellibrary.gbrt INFO     GBC trees: <sklearn.tree._tree.Tree object at 0x7f79c29c83d8>\n",
      "2018-07-11 10:41:53,815 sellibrary.gbrt INFO     GBC trees: <sklearn.tree._tree.Tree object at 0x7f79c29c8440>\n",
      "2018-07-11 10:41:53,816 sellibrary.gbrt INFO     GBC trees: <sklearn.tree._tree.Tree object at 0x7f79c29c84a8>\n",
      "2018-07-11 10:41:53,817 sellibrary.gbrt INFO     GBC trees: <sklearn.tree._tree.Tree object at 0x7f79c29c8510>\n",
      "2018-07-11 10:41:53,818 sellibrary.gbrt INFO     GBC trees: <sklearn.tree._tree.Tree object at 0x7f79c29c8578>\n",
      "2018-07-11 10:41:53,819 sellibrary.gbrt INFO     GBC trees: <sklearn.tree._tree.Tree object at 0x7f79c29c85e0>\n",
      "2018-07-11 10:41:53,820 sellibrary.gbrt INFO     GBC trees: <sklearn.tree._tree.Tree object at 0x7f79c29c8648>\n",
      "2018-07-11 10:41:53,821 sellibrary.gbrt INFO     GBC trees: <sklearn.tree._tree.Tree object at 0x7f79c29c86b0>\n",
      "2018-07-11 10:41:53,822 sellibrary.gbrt INFO     GBC trees: <sklearn.tree._tree.Tree object at 0x7f79c29c8718>\n",
      "2018-07-11 10:41:53,823 sellibrary.gbrt INFO     GBC trees: <sklearn.tree._tree.Tree object at 0x7f79c29c8780>\n",
      "2018-07-11 10:41:53,824 sellibrary.gbrt INFO     GBC trees: <sklearn.tree._tree.Tree object at 0x7f79c29c87e8>\n",
      "2018-07-11 10:41:53,825 sellibrary.gbrt INFO     GBC trees: <sklearn.tree._tree.Tree object at 0x7f79c29c8850>\n",
      "2018-07-11 10:41:53,826 sellibrary.gbrt INFO     GBC trees: <sklearn.tree._tree.Tree object at 0x7f79c29c88b8>\n",
      "2018-07-11 10:41:53,827 sellibrary.gbrt INFO     GBC trees: <sklearn.tree._tree.Tree object at 0x7f79c29c8920>\n",
      "2018-07-11 10:41:53,828 sellibrary.gbrt INFO     GBC trees: <sklearn.tree._tree.Tree object at 0x7f79c29c8988>\n",
      "2018-07-11 10:41:53,829 sellibrary.gbrt INFO     GBC trees: <sklearn.tree._tree.Tree object at 0x7f79c29c89f0>\n",
      "2018-07-11 10:41:53,830 sellibrary.gbrt INFO     GBC trees: <sklearn.tree._tree.Tree object at 0x7f79c29c8a58>\n",
      "2018-07-11 10:41:53,831 sellibrary.gbrt INFO     GBC trees: <sklearn.tree._tree.Tree object at 0x7f79c29c8ac0>\n",
      "2018-07-11 10:41:53,832 sellibrary.gbrt INFO     GBC trees: <sklearn.tree._tree.Tree object at 0x7f79c29c8b28>\n",
      "2018-07-11 10:41:53,832 sellibrary.gbrt INFO     GBC trees: <sklearn.tree._tree.Tree object at 0x7f79c29c8b90>\n",
      "2018-07-11 10:41:53,833 __main__     INFO     trained\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances\n",
      "[0.04667504 0.00918752 0.16578683 0.00130651 0.00943778 0.03267548\n",
      " 0.08152907 0.09877932 0.         0.1481458  0.01084344 0.0434201\n",
      " 0.02195101 0.03752626 0.06071199 0.10682108 0.08896789 0.\n",
      " 0.         0.         0.0012063  0.00810317 0.         0.\n",
      " 0.         0.00285814 0.         0.         0.         0.\n",
      " 0.         0.0014674  0.00612668 0.00578533 0.00133745 0.00935043]\n",
      "\n",
      "R-squared for Train: 0.15\n"
     ]
    }
   ],
   "source": [
    "def train_model():\n",
    "\n",
    "\n",
    "    X, y, docid_array, entity_id_array = load_feature_matrix(feature_filename=INTERMEDIATE_PATH + 'dexter_all_heavy_catted_8_7_2018.txt',\n",
    "                                                             feature_names=feature_names,\n",
    "                                                             entity_id_index=1,\n",
    "                                                             y_feature_index=2, \n",
    "                                                             first_feature_index=4, \n",
    "                                                             number_features_per_line=40,\n",
    "                                                             tmp_filename='/tmp/temp_conversion_file.txt'\n",
    "                                                             )\n",
    "    \n",
    "    # train only on records we have a golden salience for\n",
    "    fg = FilterGolden()\n",
    "    logger.info('X Shape = %s',X.shape)\n",
    "    logger.info('y Shape = %s',y.shape)\n",
    "    \n",
    "    dexter_dataset = DatasetDexter()\n",
    "    wikipedia_dataset = WikipediaDataset()\n",
    "\n",
    "    X2, y2, docid2, entityid2 = fg.get_only_golden_rows(X, y, docid_array, entity_id_array, dexter_dataset, wikipedia_dataset )\n",
    "\n",
    "#     X2, y2, docid2, entityid2 = fg.get_only_golden_rows(X, y, docid_array, entity_id_array)\n",
    "\n",
    "    \n",
    "    \n",
    "    wrapper = GBRTWrapper()\n",
    "    gbrt = wrapper.train_model_no_split(X2, y2,  n_estimators=40)\n",
    "    logger.info('trained')\n",
    "    #gbrt.save_model()\n",
    "\n",
    "    # from https://shankarmsy.github.io/stories/gbrt-sklearn.html\n",
    "    #One of the benefits of growing trees is that we can understand how important each of the features are \n",
    "    print (\"Feature Importances\" )\n",
    "    print (gbrt.feature_importances_) \n",
    "    print ()\n",
    "    #Let's print the R-squared value for train/test. This explains how much of the variance in the data our model is \n",
    "    #able to decipher. \n",
    "    print (\"R-squared for Train: %.2f\" %gbrt.score(X2, y2) )\n",
    "    #print (\"R-squared for Test: %.2f\" %gbrt.score(X_test, y_test) )\n",
    "    #- See more at: https://shankarmsy.github.io/stories/gbrt-sklearn.html#sthash.JNZQbnph.dpuf\n",
    "    return gbrt, X2, y2, docid2, entityid2\n",
    "    \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    gbrt, X, y, docid_array, entity_id_array = train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All right let's do this the right way. We'll use a cross-validation generator to \n",
    "# select train and CV datasets to finetune parameters such as C \n",
    "# (Regularization parameter we saw earlier). These hyperparameters are extremely critical to \n",
    "# the model. \n",
    "#Now, if we tune parameters against the Test dataset, we will end up biasing towards the test \n",
    "# set and will once again not generalize very well. We will also have no good way to find out \n",
    "# since we have essentially trained on all our data. \n",
    "#Luckily scikit-learn has builit-in packages that can help with this. We'll use a crossvalidation \n",
    "# generator that can train the model by tuning the parameters based on a cross-validation subset \n",
    "# (cv) that is picked from within the training set. A different cv subset will be picked for each iteration, we control the number of iterations. Then we will \n",
    "#use these cv/train splits and run a gridsearch function that will evaluate the model with each split and tune parameters \n",
    "#to give us the best parameter that gives the optimal result.\n",
    "\n",
    "#Defining this as a function so we can call it anytime we want\n",
    "\n",
    "\n",
    "\n",
    "def GradientBooster(param_grid, n_jobs, X, y, estimator):\n",
    "    \n",
    "    #Choose cross-validation generator - let's choose ShuffleSplit which randomly shuffles and selects Train and CV sets \n",
    "    #for each iteration. There are other methods like the KFold split.\n",
    "    cv = ShuffleSplit(X.shape[0], n_iter=10, test_size=0.2)\n",
    "    #Apply the cross-validation iterator on the Training set using GridSearchCV. This will run the classifier on the \n",
    "    #different train/cv splits using parameters specified and return the model that has the best results \n",
    "\n",
    "    # \n",
    "    #Note that we are tuning based on the F1 score 2PR/P+R where P is Precision and R is Recall. This may not always be \n",
    "    #the best score to tune our model on.  For now, we'll use F1.\n",
    "    classifier = GridSearchCV(estimator=estimator, cv=cv, param_grid=param_grid, n_jobs=n_jobs)\n",
    "    #Also note that we're feeding multiple neighbors to the GridSearch to try out. \n",
    "    #We'll now fit the training dataset to this classifier\n",
    "    classifier.fit(X, y)\n",
    "    #Let's look at the best estimator that was found by GridSearchCV\n",
    "    print (\"Best Estimator learned through GridSearch\")\n",
    "    print ( classifier.best_estimator_)\n",
    "    return cv, classifier.best_estimator_, classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn import cross_validation \n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.datasets import load_digits \n",
    "from sklearn.learning_curve import learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None, n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)): \n",
    "    \n",
    "    \"\"\" Generate a simple plot of the test and traning learning curve. \n",
    "    Parameters ---------- \n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods An object of that type which is cloned for each validation. \n",
    "    title : string Title for the chart. \n",
    "    X : array-like, shape (n_samples, n_features) Training vector, where n_samples is the number of samples and n_features is the number of features. \n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional Target relative to X for classification or regression; None for unsupervised learning. \n",
    "    ylim : tuple, shape (ymin, ymax), optional Defines minimum and maximum yvalues plotted. \n",
    "    cv : integer, cross-validation generator, optional If an integer is passed, it is the number of folds (defaults to 3). Specific cross-validation objects can be passed, see sklearn.cross_validation module for the list of possible objects \n",
    "    n_jobs : integer, optional Number of jobs to run in parallel (default 1). \"\"\" \n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None: plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1,\n",
    "                     color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_info(best_est, X, y, tset):\n",
    "    print (\"--------------------------------\" )\n",
    "    print (tset+\" Best Estimator Parameters\" )\n",
    "    print (\"--------------------------------\" )\n",
    "    print (\"n_estimators: %d\" %best_est.n_estimators )\n",
    "    print (\"max_depth: %d\" %best_est.max_depth )\n",
    "    print (\"min_samples_leaf: %d\" %best_est.min_samples_leaf )\n",
    "    print (\"max_features: %.2f\" %best_est.max_features )\n",
    "    print (tset+\" R-squared: %.2f\" %best_est.score(X,y) )     \n",
    "    print (\"Learning Rate: %.2f\" %best_est.learning_rate )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import ShuffleSplit, train_test_split \n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-11 10:47:37,693 __main__     INFO     starting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: JOBLIB_TEMP_FOLDER=/tmp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-11 10:48:32,458 __main__     INFO     complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator learned through GridSearch\n",
      "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "             learning_rate=0.05, loss='ls', max_depth=12, max_features=0.4,\n",
      "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "             min_impurity_split=None, min_samples_leaf=18,\n",
      "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "             n_estimators=25, presort='auto', random_state=None,\n",
      "             subsample=1.0, verbose=0, warm_start=False)\n",
      "--------------------------------\n",
      ".8CV Best Estimator Parameters\n",
      "--------------------------------\n",
      "n_estimators: 25\n",
      "max_depth: 12\n",
      "min_samples_leaf: 18\n",
      "max_features: 0.40\n",
      ".8CV R-squared: 0.27\n",
      "Learning Rate: 0.05\n"
     ]
    }
   ],
   "source": [
    "# if no space left on device, try setting the env ver JOBLIB_TEMP_FOLDER to /tmp\n",
    "%env JOBLIB_TEMP_FOLDER=/tmp\n",
    "#WARNING - THIS MIGHT TAKE A WHILE TO RUN. \n",
    "# TRY ADJUSTING parameters such as n_jobs (jobs to run in parallel, before \n",
    "#increasing this make sure your system can handle it), n_iter for ShuffleSplit \n",
    "# (in the function definition) and reducing #number of values being tried for max_depth/n_estimators. \n",
    "#SELECT INTERRUPT IN THE MENU AND PRESS INTERRUPT KERNEL IF YOU NEEDD TO STOP EXECUTION \n",
    "logger.info('starting')\n",
    "\n",
    "param_grid={'n_estimators':[25, 50, 250], # tried 250, 100, [50], 25\n",
    "            'learning_rate': [0.05, 0.02],# tried 0.2, 0.1, [0.05], 0.02, 0.01],\n",
    "            'max_depth':[9, 12], # tried 6,[9],12\n",
    "            'min_samples_leaf':[18, 20, 22], # tried  2,5,9,12,15,[18]\n",
    "            'max_features':[0.3,0.4] # tried 0.2,[0.3],0.4,0.5\n",
    "           } \n",
    "n_jobs = 4 \n",
    "\n",
    "wrapper = GBRTWrapper()\n",
    "X_train, X_test, y_train, y_test = wrapper.get_test_train_datasets(X,y,entity_id_array,7,train_split=0.95)\n",
    "\n",
    "#Let's fit GBRT to the digits training dataset by calling the function we just created. \n",
    "estimator = GradientBoostingRegressor()\n",
    "\n",
    "cv, best_est, trained_model=GradientBooster(param_grid, n_jobs, X, y, estimator) \n",
    "logger.info('complete')\n",
    "print_info(best_est, X, y, '.8CV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try it for trees\n",
    "\n",
    "# # if no space left on device, try setting the env ver JOBLIB_TEMP_FOLDER to /tmp\n",
    "# %env JOBLIB_TEMP_FOLDER=/tmp\n",
    "# logger.info('starting')\n",
    "# param_grid={'n_estimators':[25, 50, 250], # tried 250, 100, [50], 25\n",
    "#             'max_depth':[9, 12, 15, 20], # tried 6,[9],12\n",
    "#             'min_samples_leaf':[20, 22, 25, 30], # tried  2,5,9,12,15,[18]\n",
    "#             'max_features':[0.5,0.6,0.7] # tried 0.2,[0.3],0.4,0.5\n",
    "#            } \n",
    "# n_jobs = 4 \n",
    "# wrapper = GBRTWrapper()\n",
    "# X_train, X_test, y_train, y_test = wrapper.get_test_train_datasets(X,y,entity_id_array,7,train_split=0.95)\n",
    "# #Let's fit GBRT to the digits training dataset by calling the function we just created. \n",
    "# estimator = ExtraTreesRegressor()\n",
    "# cv, best_est=GradientBooster(param_grid, n_jobs, X, y, estimator) \n",
    "# logger.info('complete')\n",
    "# print_info(best_est, X, y, '.8CV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Train Best Estimator Parameters\n",
      "--------------------------------\n",
      "n_estimators: 25\n",
      "max_depth: 12\n",
      "min_samples_leaf: 18\n",
      "max_features: 0.40\n",
      "Train R-squared: 0.27\n",
      "Learning Rate: 0.05\n",
      "--------------------------------\n",
      "Test Best Estimator Parameters\n",
      "--------------------------------\n",
      "n_estimators: 25\n",
      "max_depth: 12\n",
      "min_samples_leaf: 18\n",
      "max_features: 0.40\n",
      "Test R-squared: 0.24\n",
      "Learning Rate: 0.05\n",
      "--------------------------------\n",
      "All Best Estimator Parameters\n",
      "--------------------------------\n",
      "n_estimators: 25\n",
      "max_depth: 12\n",
      "min_samples_leaf: 18\n",
      "max_features: 0.40\n",
      "All R-squared: 0.27\n",
      "Learning Rate: 0.05\n"
     ]
    }
   ],
   "source": [
    "print_info(best_est, X_train, y_train, 'Train')\n",
    "print_info(best_est, X_test, y_test, 'Test')\n",
    "print_info(best_est, X, y, 'All')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Estimator Parameters (with all data with false zeros introduced)\n",
    "---------------------------\n",
    "n_estimators: 100\n",
    "Learning Rate: 0.10\n",
    "max_depth: 6\n",
    "min_samples_leaf: 9\n",
    "max_features: 0.30\n",
    "Train R-squared: 0.64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-11 10:49:27,674 __main__     INFO     starting\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "ename": "JoblibIndexError",
     "evalue": "JoblibIndexError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.6/site-packages/ipykernel/__main__.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x7f7a8f2b26f0, file \"/...3.6/site-packages/ipykernel/__main__.py\", line 1>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/opt/anaconda/envs/Python3/lib/python3.6/site-packages/ipykernel/__pycache__/__main__.cpython-36.pyc', '__doc__': None, '__file__': '/opt/anaconda/envs/Python3/lib/python3.6/site-packages/ipykernel/__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.6/site-packages/ipykernel/__main__.py'), 'app': <module 'ipykernel.kernelapp' from '/opt/anacond.../python3.6/site-packages/ipykernel/kernelapp.py'>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.6/site-packages/ipykernel/__main__.py'), pkg_name='ipykernel', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7f7a8f2b26f0, file \"/...3.6/site-packages/ipykernel/__main__.py\", line 1>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/opt/anaconda/envs/Python3/lib/python3.6/site-packages/ipykernel/__pycache__/__main__.cpython-36.pyc', '__doc__': None, '__file__': '/opt/anaconda/envs/Python3/lib/python3.6/site-packages/ipykernel/__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.6/site-packages/ipykernel/__main__.py'), 'app': <module 'ipykernel.kernelapp' from '/opt/anacond.../python3.6/site-packages/ipykernel/kernelapp.py'>}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/ipykernel/__main__.py in <module>()\n      1 if __name__ == '__main__':\n      2     from ipykernel import kernelapp as app\n----> 3     app.launch_new_instance()\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/tornado/platform/asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    122         except (RuntimeError, AssertionError):\n    123             old_loop = None\n    124         try:\n    125             self._setup_logging()\n    126             asyncio.set_event_loop(self.asyncio_loop)\n--> 127             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Uni...EventLoop running=True closed=False debug=False>>\n    128         finally:\n    129             asyncio.set_event_loop(old_loop)\n    130 \n    131     def stop(self):\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/asyncio/base_events.py in run_forever(self=<_UnixSelectorEventLoop running=True closed=False debug=False>)\n    417             sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    418                                    finalizer=self._asyncgen_finalizer_hook)\n    419         try:\n    420             events._set_running_loop(self)\n    421             while True:\n--> 422                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_UnixS...EventLoop running=True closed=False debug=False>>\n    423                 if self._stopping:\n    424                     break\n    425         finally:\n    426             self._stopping = False\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/asyncio/base_events.py in _run_once(self=<_UnixSelectorEventLoop running=True closed=False debug=False>)\n   1427                         logger.warning('Executing %s took %.3f seconds',\n   1428                                        _format_handle(handle), dt)\n   1429                 finally:\n   1430                     self._current_handle = None\n   1431             else:\n-> 1432                 handle._run()\n        handle._run = <bound method Handle._run of <Handle BaseAsyncIOLoop._handle_events(11, 1)>>\n   1433         handle = None  # Needed to break cycles when an exception occurs.\n   1434 \n   1435     def _set_coroutine_wrapper(self, enabled):\n   1436         try:\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/asyncio/events.py in _run(self=<Handle BaseAsyncIOLoop._handle_events(11, 1)>)\n    140             self._callback = None\n    141             self._args = None\n    142 \n    143     def _run(self):\n    144         try:\n--> 145             self._callback(*self._args)\n        self._callback = <bound method BaseAsyncIOLoop._handle_events of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (11, 1)\n    146         except Exception as exc:\n    147             cb = _format_callback_source(self._callback, self._args)\n    148             msg = 'Exception in callback {}'.format(cb)\n    149             context = {\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/tornado/platform/asyncio.py in _handle_events(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, fd=11, events=1)\n    112             self.writers.remove(fd)\n    113         del self.handlers[fd]\n    114 \n    115     def _handle_events(self, fd, events):\n    116         fileobj, handler_func = self.handlers[fd]\n--> 117         handler_func(fileobj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fileobj = <zmq.sugar.socket.Socket object>\n        events = 1\n    118 \n    119     def start(self):\n    120         try:\n    121             old_loop = asyncio.get_event_loop()\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"#OK we'll now call the plot_learning_curve modul...g rate even further to address any overfitting. \\n\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 7, 11, 10, 49, 27, 669785, tzinfo=tzlocal()), 'msg_id': '1cfb2f6ff68f419e80b9c9c74ac650c8', 'msg_type': 'execute_request', 'session': '18d55d334c6240f98c2713286b64cdb2', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '1cfb2f6ff68f419e80b9c9c74ac650c8', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'18d55d334c6240f98c2713286b64cdb2']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"#OK we'll now call the plot_learning_curve modul...g rate even further to address any overfitting. \\n\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 7, 11, 10, 49, 27, 669785, tzinfo=tzlocal()), 'msg_id': '1cfb2f6ff68f419e80b9c9c74ac650c8', 'msg_type': 'execute_request', 'session': '18d55d334c6240f98c2713286b64cdb2', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '1cfb2f6ff68f419e80b9c9c74ac650c8', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'18d55d334c6240f98c2713286b64cdb2'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"#OK we'll now call the plot_learning_curve modul...g rate even further to address any overfitting. \\n\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 7, 11, 10, 49, 27, 669785, tzinfo=tzlocal()), 'msg_id': '1cfb2f6ff68f419e80b9c9c74ac650c8', 'msg_type': 'execute_request', 'session': '18d55d334c6240f98c2713286b64cdb2', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '1cfb2f6ff68f419e80b9c9c74ac650c8', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"#OK we'll now call the plot_learning_curve modul...g rate even further to address any overfitting. \\n\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"#OK we'll now call the plot_learning_curve modul...g rate even further to address any overfitting. \\n\"\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"#OK we'll now call the plot_learning_curve modul...g rate even further to address any overfitting. \\n\",), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"#OK we'll now call the plot_learning_curve modul...g rate even further to address any overfitting. \\n\",)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"#OK we'll now call the plot_learning_curve modul...g rate even further to address any overfitting. \\n\", store_history=True, silent=False, shell_futures=True)\n   2657         -------\n   2658         result : :class:`ExecutionResult`\n   2659         \"\"\"\n   2660         try:\n   2661             result = self._run_cell(\n-> 2662                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = \"#OK we'll now call the plot_learning_curve modul...g rate even further to address any overfitting. \\n\"\n        store_history = True\n        silent = False\n        shell_futures = True\n   2663         finally:\n   2664             self.events.trigger('post_execute')\n   2665             if not silent:\n   2666                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"#OK we'll now call the plot_learning_curve modul...g rate even further to address any overfitting. \\n\", store_history=True, silent=False, shell_futures=True)\n   2780                 self.displayhook.exec_result = result\n   2781 \n   2782                 # Execute the user code\n   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2786                 \n   2787                 self.last_execution_succeeded = not has_raised\n   2788                 self.last_execution_result = result\n   2789 \n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Expr object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>], cell_name='<ipython-input-30-a2a084748d3a>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7f7a52cdb240, executi...rue silent=False shell_futures=True> result=None>)\n   2898 \n   2899         try:\n   2900             for i, node in enumerate(to_run_exec):\n   2901                 mod = ast.Module([node])\n   2902                 code = compiler(mod, cell_name, \"exec\")\n-> 2903                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f7a51e98270, file \"<ipython-input-30-a2a084748d3a>\", line 14>\n        result = <ExecutionResult object at 7f7a52cdb240, executi...rue silent=False shell_futures=True> result=None>\n   2904                     return True\n   2905 \n   2906             for i, node in enumerate(to_run_interactive):\n   2907                 mod = ast.Interactive([node])\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f7a51e98270, file \"<ipython-input-30-a2a084748d3a>\", line 14>, result=<ExecutionResult object at 7f7a52cdb240, executi...rue silent=False shell_futures=True> result=None>)\n   2958         outflag = True  # happens in more places, so it's easier as default\n   2959         try:\n   2960             try:\n   2961                 self.hooks.pre_run_code_hook()\n   2962                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2963                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f7a51e98270, file \"<ipython-input-30-a2a084748d3a>\", line 14>\n        self.user_global_ns = {'DatasetDexter': <class 'sellibrary.sel.dexter_dataset.DatasetDexter'>, 'ExtraTreesRegressor': <class 'sklearn.ensemble.forest.ExtraTreesRegressor'>, 'FileLocations': <class 'sellibrary.locations.FileLocations'>, 'FilterGolden': <class 'sellibrary.filter_only_golden.FilterGolden'>, 'GBRTWrapper': <class 'sellibrary.gbrt.GBRTWrapper'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, 'GradientBooster': <function GradientBooster>, 'GradientBoostingRegressor': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>, 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'INTERMEDIATE_PATH': '/project/Dropbox/Datasets/intermediate/', ...}\n        self.user_ns = {'DatasetDexter': <class 'sellibrary.sel.dexter_dataset.DatasetDexter'>, 'ExtraTreesRegressor': <class 'sklearn.ensemble.forest.ExtraTreesRegressor'>, 'FileLocations': <class 'sellibrary.locations.FileLocations'>, 'FilterGolden': <class 'sellibrary.filter_only_golden.FilterGolden'>, 'GBRTWrapper': <class 'sellibrary.gbrt.GBRTWrapper'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, 'GradientBooster': <function GradientBooster>, 'GradientBoostingRegressor': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>, 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'INTERMEDIATE_PATH': '/project/Dropbox/Datasets/intermediate/', ...}\n   2964             finally:\n   2965                 # Reset our crash handler in place\n   2966                 sys.excepthook = old_excepthook\n   2967         except SystemExit as e:\n\n...........................................................................\n/project/TX-Jupiter-Notebooks/UCL_COMPGB99/<ipython-input-30-a2a084748d3a> in <module>()\n      9 gbr_estimator = GradientBoostingRegressor(n_estimators=best_est.n_estimators, \n     10                                       max_depth=best_est.max_depth, \n     11                                       learning_rate=best_est.learning_rate, \n     12                                       min_samples_leaf=best_est.min_samples_leaf, \n     13                                       max_features=best_est.max_features) \n---> 14 plot_learning_curve(trained_model, title, X, y, cv=cv, n_jobs=n_jobs) \n     15 \n     16 plt.show() \n     17 logger.info('complete')\n     18 \n\n...........................................................................\n/project/TX-Jupiter-Notebooks/UCL_COMPGB99/<ipython-input-23-843abeac6091> in plot_learning_curve(estimator=GridSearchCV(cv=ShuffleSplit(1940, n_iter=10, te...='2*n_jobs', refit=True, scoring=None, verbose=0), title='Learning Curves (Gradient Boosted Regression Trees)', X=array([[364.,   2., 243., ...,   0.,   0.,   0.]...      [877.,   2., 101., ...,   0.,   0.,   0.]]), y=array([3.  , 3.  , 2.  , ..., 1.25, 1.75, 1.25]), ylim=None, cv=ShuffleSplit(1940, n_iter=10, test_size=0.2, random_state=None), n_jobs=4, train_sizes=array([0.1  , 0.325, 0.55 , 0.775, 1.   ]))\n     12     plt.figure()\n     13     plt.title(title)\n     14     if ylim is not None: plt.ylim(*ylim)\n     15     plt.xlabel(\"Training examples\")\n     16     plt.ylabel(\"Score\")\n---> 17     train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n     18     train_scores_mean = np.mean(train_scores, axis=1)\n     19     train_scores_std = np.std(train_scores, axis=1)\n     20     test_scores_mean = np.mean(test_scores, axis=1)\n     21     test_scores_std = np.std(test_scores, axis=1)\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/learning_curve.py in learning_curve(estimator=GridSearchCV(cv=ShuffleSplit(1940, n_iter=10, te...='2*n_jobs', refit=True, scoring=None, verbose=0), X=array([[364.,   2., 243., ...,   0.,   0.,   0.]...      [877.,   2., 101., ...,   0.,   0.,   0.]]), y=array([3.  , 3.  , 2.  , ..., 1.25, 1.75, 1.25]), train_sizes=array([0.1  , 0.325, 0.55 , 0.775, 1.   ]), cv=[(array([ 755,  597, 1098, ...,  909,  190,  295]), array([ 458,  247, 1333, 1902, 1922, 1052,  680,...1078,  894, 1485, 1599,\n        326, 1374,  963])), (array([1305, 1038,   12, ...,  199,  552,  414]), array([  86,  104, 1355,  977,  961, 1705, 1749,...1930,  513,  177, 1686,\n        387,  746,  992])), (array([1861,  713,  212, ...,  224, 1028, 1781]), array([ 125,  540, 1935,  199,  375,   11,  980,...1247,  956, 1541, 1489,\n        767,    5, 1246])), (array([1090, 1684,  882, ..., 1688, 1121, 1829]), array([1155,  947,  819,  125, 1621, 1740,  746,... 167, 1324, 1868,   97,\n        897,  109, 1400])), (array([1884,  429,  785, ..., 1437,  231, 1915]), array([ 660,  963, 1116,    0,  652,  607, 1193,... 520,  152, 1611,  813,\n        788, 1908, 1282])), (array([ 655,  292,  835, ..., 1481,  465,  437]), array([ 308, 1657,  746,   33, 1017, 1329, 1328,... 457,  276, 1656, 1936,\n       1349,  217, 1798])), (array([ 304, 1432,   76, ..., 1345,  640,  705]), array([ 268,   22, 1214, 1436, 1128,  122,  180,...1512,  729, 1548, 1392,\n        772, 1258, 1866])), (array([1778, 1342,   57, ..., 1508, 1618,   18]), array([ 280, 1519,  382, 1813, 1302,  801,  212,...1538, 1445, 1368,   21,\n         96,  262,  825])), (array([1678, 1604,  201, ...,  813, 1411,  423]), array([1546,  386,  928, 1331,  200,  133,  322,...1671, 1284, 1237,  564,\n        772, 1279, 1082])), (array([ 803, 1749, 1576, ..., 1342, 1819, 1438]), array([1456,  250,  307,  677, 1555, 1453,  299,...1081,  669,  604,  447,\n        214, 1296, 1233]))], scoring=None, exploit_incremental_learning=False, n_jobs=4, pre_dispatch='all', verbose=0, error_score='raise')\n    166     else:\n    167         out = parallel(delayed(_fit_and_score)(\n    168             clone(estimator), X, y, scorer, train[:n_train_samples], test,\n    169             verbose, parameters=None, fit_params=None, return_train_score=True,\n    170             error_score=error_score)\n--> 171             for train, test in cv for n_train_samples in train_sizes_abs)\n        cv = [(array([ 755,  597, 1098, ...,  909,  190,  295]), array([ 458,  247, 1333, 1902, 1922, 1052,  680,...1078,  894, 1485, 1599,\n        326, 1374,  963])), (array([1305, 1038,   12, ...,  199,  552,  414]), array([  86,  104, 1355,  977,  961, 1705, 1749,...1930,  513,  177, 1686,\n        387,  746,  992])), (array([1861,  713,  212, ...,  224, 1028, 1781]), array([ 125,  540, 1935,  199,  375,   11,  980,...1247,  956, 1541, 1489,\n        767,    5, 1246])), (array([1090, 1684,  882, ..., 1688, 1121, 1829]), array([1155,  947,  819,  125, 1621, 1740,  746,... 167, 1324, 1868,   97,\n        897,  109, 1400])), (array([1884,  429,  785, ..., 1437,  231, 1915]), array([ 660,  963, 1116,    0,  652,  607, 1193,... 520,  152, 1611,  813,\n        788, 1908, 1282])), (array([ 655,  292,  835, ..., 1481,  465,  437]), array([ 308, 1657,  746,   33, 1017, 1329, 1328,... 457,  276, 1656, 1936,\n       1349,  217, 1798])), (array([ 304, 1432,   76, ..., 1345,  640,  705]), array([ 268,   22, 1214, 1436, 1128,  122,  180,...1512,  729, 1548, 1392,\n        772, 1258, 1866])), (array([1778, 1342,   57, ..., 1508, 1618,   18]), array([ 280, 1519,  382, 1813, 1302,  801,  212,...1538, 1445, 1368,   21,\n         96,  262,  825])), (array([1678, 1604,  201, ...,  813, 1411,  423]), array([1546,  386,  928, 1331,  200,  133,  322,...1671, 1284, 1237,  564,\n        772, 1279, 1082])), (array([ 803, 1749, 1576, ..., 1342, 1819, 1438]), array([1456,  250,  307,  677, 1555, 1453,  299,...1081,  669,  604,  447,\n        214, 1296, 1233]))]\n    172         out = np.array(out)[:, :2]\n    173         n_cv_folds = out.shape[0] // n_unique_ticks\n    174         out = out.reshape(n_cv_folds, n_unique_ticks, 2)\n    175 \n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=4), iterable=<generator object learning_curve.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=4)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nIndexError                                         Wed Jul 11 10:49:27 2018\nPID: 4811               Python 3.6.5: /opt/anaconda/envs/Python3/bin/python\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (GridSearchCV(cv=ShuffleSplit(1940, n_iter=10, te...='2*n_jobs', refit=True, scoring=None, verbose=0), array([[364.,   2., 243., ...,   0.,   0.,   0.]...      [877.,   2., 101., ...,   0.,   0.,   0.]]), array([3.  , 3.  , 2.  , ..., 1.25, 1.75, 1.25]), <function _passthrough_scorer>, array([ 755,  597, 1098,  652,  698,   65, 1116,... 769,  724, 1210,   89,  413,  941,\n        697]), array([ 458,  247, 1333, 1902, 1922, 1052,  680,...1078,  894, 1485, 1599,\n        326, 1374,  963]), 0), {'error_score': 'raise', 'fit_params': None, 'parameters': None, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (GridSearchCV(cv=ShuffleSplit(1940, n_iter=10, te...='2*n_jobs', refit=True, scoring=None, verbose=0), array([[364.,   2., 243., ...,   0.,   0.,   0.]...      [877.,   2., 101., ...,   0.,   0.,   0.]]), array([3.  , 3.  , 2.  , ..., 1.25, 1.75, 1.25]), <function _passthrough_scorer>, array([ 755,  597, 1098,  652,  698,   65, 1116,... 769,  724, 1210,   89,  413,  941,\n        697]), array([ 458,  247, 1333, 1902, 1922, 1052,  680,...1078,  894, 1485, 1599,\n        326, 1374,  963]), 0)\n        kwargs = {'error_score': 'raise', 'fit_params': None, 'parameters': None, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/cross_validation.py in _fit_and_score(estimator=GridSearchCV(cv=ShuffleSplit(1940, n_iter=10, te...='2*n_jobs', refit=True, scoring=None, verbose=0), X=array([[364.,   2., 243., ...,   0.,   0.,   0.]...      [877.,   2., 101., ...,   0.,   0.,   0.]]), y=array([3.  , 3.  , 2.  , ..., 1.25, 1.75, 1.25]), scorer=<function _passthrough_scorer>, train=array([ 755,  597, 1098,  652,  698,   65, 1116,... 769,  724, 1210,   89,  413,  941,\n        697]), test=array([ 458,  247, 1333, 1902, 1922, 1052,  680,...1078,  894, 1485, 1599,\n        326, 1374,  963]), verbose=0, parameters=None, fit_params={}, return_train_score=True, return_parameters=False, error_score='raise')\n   1670 \n   1671     try:\n   1672         if y_train is None:\n   1673             estimator.fit(X_train, **fit_params)\n   1674         else:\n-> 1675             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method GridSearchCV.fit of GridSearchCV(c...'2*n_jobs', refit=True, scoring=None, verbose=0)>\n        X_train = array([[4.480e+02, 2.000e+00, 6.000e+01, ..., 0...., ..., 0.000e+00, 0.000e+00,\n        0.000e+00]])\n        y_train = array([2.33, 2.67, 1.  , 1.33, 2.67, 1.  , 2.  ,...1.33, 2.33, 2.75, 1.67, 1.25, 1.67,\n       2.33])\n        fit_params = {}\n   1676 \n   1677     except Exception as e:\n   1678         if error_score == 'raise':\n   1679             raise\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/grid_search.py in fit(self=GridSearchCV(cv=ShuffleSplit(1940, n_iter=10, te...='2*n_jobs', refit=True, scoring=None, verbose=0), X=array([[4.480e+02, 2.000e+00, 6.000e+01, ..., 0...., ..., 0.000e+00, 0.000e+00,\n        0.000e+00]]), y=array([2.33, 2.67, 1.  , 1.33, 2.67, 1.  , 2.  ,...1.33, 2.33, 2.75, 1.67, 1.25, 1.67,\n       2.33]))\n    833         y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n    834             Target relative to X for classification or regression;\n    835             None for unsupervised learning.\n    836 \n    837         \"\"\"\n--> 838         return self._fit(X, y, ParameterGrid(self.param_grid))\n        self._fit = <bound method BaseSearchCV._fit of GridSearchCV(...'2*n_jobs', refit=True, scoring=None, verbose=0)>\n        X = array([[4.480e+02, 2.000e+00, 6.000e+01, ..., 0...., ..., 0.000e+00, 0.000e+00,\n        0.000e+00]])\n        y = array([2.33, 2.67, 1.  , 1.33, 2.67, 1.  , 2.  ,...1.33, 2.33, 2.75, 1.67, 1.25, 1.67,\n       2.33])\n        self.param_grid = {'learning_rate': [0.05, 0.02], 'max_depth': [9, 12], 'max_features': [0.3, 0.4], 'min_samples_leaf': [18, 20, 22], 'n_estimators': [25, 50, 250]}\n    839 \n    840 \n    841 class RandomizedSearchCV(BaseSearchCV):\n    842     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/grid_search.py in _fit(self=GridSearchCV(cv=ShuffleSplit(1940, n_iter=10, te...='2*n_jobs', refit=True, scoring=None, verbose=0), X=array([[4.480e+02, 2.000e+00, 6.000e+01, ..., 0...., ..., 0.000e+00, 0.000e+00,\n        0.000e+00]]), y=array([2.33, 2.67, 1.  , 1.33, 2.67, 1.  , 2.  ,...1.33, 2.33, 2.75, 1.67, 1.25, 1.67,\n       2.33]), parameter_iterable=<sklearn.grid_search.ParameterGrid object>)\n    569         )(\n    570             delayed(_fit_and_score)(clone(base_estimator), X, y, self.scorer_,\n    571                                     train, test, self.verbose, parameters,\n    572                                     self.fit_params, return_parameters=True,\n    573                                     error_score=self.error_score)\n--> 574                 for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.grid_search.ParameterGrid object>\n    575                 for train, test in cv)\n    576 \n    577         # Out is a list of triplet: score, estimator, n_test_samples\n    578         n_fits = len(out)\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=4), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    774         self.n_completed_tasks = 0\n    775         try:\n    776             # Only set self._iterating to True if at least a batch\n    777             # was dispatched. In particular this covers the edge\n    778             # case of Parallel used with an exhausted iterator.\n--> 779             while self.dispatch_one_batch(iterator):\n        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=4)>\n        iterator = <generator object BaseSearchCV._fit.<locals>.<genexpr>>\n    780                 self._iterating = True\n    781             else:\n    782                 self._iterating = False\n    783 \n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=4), iterator=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    620             tasks = BatchedCalls(itertools.islice(iterator, batch_size))\n    621             if len(tasks) == 0:\n    622                 # No more tasks available in the iterator: tell caller to stop.\n    623                 return False\n    624             else:\n--> 625                 self._dispatch(tasks)\n        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=4)>\n        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    626                 return True\n    627 \n    628     def _print(self, msg, msg_args):\n    629         \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=4), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    583         self.n_dispatched_tasks += len(batch)\n    584         self.n_dispatched_batches += 1\n    585 \n    586         dispatch_timestamp = time.time()\n    587         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)\n--> 588         job = self._backend.apply_async(batch, callback=cb)\n        job = undefined\n        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>\n    589         self._jobs.append(job)\n    590 \n    591     def dispatch_next(self):\n    592         \"\"\"Dispatch more data for parallel processing\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)\n    106             raise ValueError('n_jobs == 0 in Parallel has no meaning')\n    107         return 1\n    108 \n    109     def apply_async(self, func, callback=None):\n    110         \"\"\"Schedule a func to be run\"\"\"\n--> 111         result = ImmediateResult(func)\n        result = undefined\n        func = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    112         if callback:\n    113             callback(result)\n    114         return result\n    115 \n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    327 \n    328 class ImmediateResult(object):\n    329     def __init__(self, batch):\n    330         # Don't delay the application, to avoid keeping the input\n    331         # arguments in memory\n--> 332         self.results = batch()\n        self.results = undefined\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    333 \n    334     def get(self):\n    335         return self.results\n    336 \n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (GradientBoostingRegressor(alpha=0.9, criterion='...      subsample=1.0, verbose=0, warm_start=False), array([[4.480e+02, 2.000e+00, 6.000e+01, ..., 0...., ..., 0.000e+00, 0.000e+00,\n        0.000e+00]]), array([2.33, 2.67, 1.  , 1.33, 2.67, 1.  , 2.  ,...1.33, 2.33, 2.75, 1.67, 1.25, 1.67,\n       2.33]), <function _passthrough_scorer>, array([ 134, 1492,  891, ..., 1777,  323, 1307]), array([1054,  714, 1056,  342, 1085,  782,   17,... 774, 1539, 1057,  282,\n       1494, 1031,  525]), 0, {'learning_rate': 0.05, 'max_depth': 9, 'max_features': 0.3, 'min_samples_leaf': 18, 'n_estimators': 25}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (GradientBoostingRegressor(alpha=0.9, criterion='...      subsample=1.0, verbose=0, warm_start=False), array([[4.480e+02, 2.000e+00, 6.000e+01, ..., 0...., ..., 0.000e+00, 0.000e+00,\n        0.000e+00]]), array([2.33, 2.67, 1.  , 1.33, 2.67, 1.  , 2.  ,...1.33, 2.33, 2.75, 1.67, 1.25, 1.67,\n       2.33]), <function _passthrough_scorer>, array([ 134, 1492,  891, ..., 1777,  323, 1307]), array([1054,  714, 1056,  342, 1085,  782,   17,... 774, 1539, 1057,  282,\n       1494, 1031,  525]), 0, {'learning_rate': 0.05, 'max_depth': 9, 'max_features': 0.3, 'min_samples_leaf': 18, 'n_estimators': 25}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/cross_validation.py in _fit_and_score(estimator=GradientBoostingRegressor(alpha=0.9, criterion='...      subsample=1.0, verbose=0, warm_start=False), X=array([[4.480e+02, 2.000e+00, 6.000e+01, ..., 0...., ..., 0.000e+00, 0.000e+00,\n        0.000e+00]]), y=array([2.33, 2.67, 1.  , 1.33, 2.67, 1.  , 2.  ,...1.33, 2.33, 2.75, 1.67, 1.25, 1.67,\n       2.33]), scorer=<function _passthrough_scorer>, train=array([ 134, 1492,  891, ..., 1777,  323, 1307]), test=array([1054,  714, 1056,  342, 1085,  782,   17,... 774, 1539, 1057,  282,\n       1494, 1031,  525]), verbose=0, parameters={'learning_rate': 0.05, 'max_depth': 9, 'max_features': 0.3, 'min_samples_leaf': 18, 'n_estimators': 25}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1663     if parameters is not None:\n   1664         estimator.set_params(**parameters)\n   1665 \n   1666     start_time = time.time()\n   1667 \n-> 1668     X_train, y_train = _safe_split(estimator, X, y, train)\n        X_train = undefined\n        y_train = undefined\n        estimator = GradientBoostingRegressor(alpha=0.9, criterion='...      subsample=1.0, verbose=0, warm_start=False)\n        X = array([[4.480e+02, 2.000e+00, 6.000e+01, ..., 0...., ..., 0.000e+00, 0.000e+00,\n        0.000e+00]])\n        y = array([2.33, 2.67, 1.  , 1.33, 2.67, 1.  , 2.  ,...1.33, 2.33, 2.75, 1.67, 1.25, 1.67,\n       2.33])\n        train = array([ 134, 1492,  891, ..., 1777,  323, 1307])\n   1669     X_test, y_test = _safe_split(estimator, X, y, test, train)\n   1670 \n   1671     try:\n   1672         if y_train is None:\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/cross_validation.py in _safe_split(estimator=GradientBoostingRegressor(alpha=0.9, criterion='...      subsample=1.0, verbose=0, warm_start=False), X=array([[4.480e+02, 2.000e+00, 6.000e+01, ..., 0...., ..., 0.000e+00, 0.000e+00,\n        0.000e+00]]), y=array([2.33, 2.67, 1.  , 1.33, 2.67, 1.  , 2.  ,...1.33, 2.33, 2.75, 1.67, 1.25, 1.67,\n       2.33]), indices=array([ 134, 1492,  891, ..., 1777,  323, 1307]), train_indices=None)\n   1731             if train_indices is None:\n   1732                 X_subset = X[np.ix_(indices, indices)]\n   1733             else:\n   1734                 X_subset = X[np.ix_(indices, train_indices)]\n   1735         else:\n-> 1736             X_subset = safe_indexing(X, indices)\n        X_subset = undefined\n        X = array([[4.480e+02, 2.000e+00, 6.000e+01, ..., 0...., ..., 0.000e+00, 0.000e+00,\n        0.000e+00]])\n        indices = array([ 134, 1492,  891, ..., 1777,  323, 1307])\n   1737 \n   1738     if y is not None:\n   1739         y_subset = safe_indexing(y, indices)\n   1740     else:\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/utils/__init__.py in safe_indexing(X=array([[4.480e+02, 2.000e+00, 6.000e+01, ..., 0...., ..., 0.000e+00, 0.000e+00,\n        0.000e+00]]), indices=array([ 134, 1492,  891, ..., 1777,  323, 1307]))\n    155             return X.copy().iloc[indices]\n    156     elif hasattr(X, \"shape\"):\n    157         if hasattr(X, 'take') and (hasattr(indices, 'dtype') and\n    158                                    indices.dtype.kind == 'i'):\n    159             # This is often substantially faster than X[indices]\n--> 160             return X.take(indices, axis=0)\n        X.take = <built-in method take of numpy.ndarray object>\n        indices = array([ 134, 1492,  891, ..., 1777,  323, 1307])\n    161         else:\n    162             return X[indices]\n    163     else:\n    164         return [X[idx] for idx in indices]\n\nIndexError: index 1492 is out of bounds for size 155\n___________________________________________________________________________",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/cross_validation.py\", line 1675, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/grid_search.py\", line 838, in fit\n    return self._fit(X, y, ParameterGrid(self.param_grid))\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/grid_search.py\", line 574, in _fit\n    for parameters in parameter_iterable\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 779, in __call__\n    while self.dispatch_one_batch(iterator):\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 625, in dispatch_one_batch\n    self._dispatch(tasks)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 588, in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 111, in apply_async\n    result = ImmediateResult(func)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 332, in __init__\n    self.results = batch()\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/cross_validation.py\", line 1668, in _fit_and_score\n    X_train, y_train = _safe_split(estimator, X, y, train)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/cross_validation.py\", line 1736, in _safe_split\n    X_subset = safe_indexing(X, indices)\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/utils/__init__.py\", line 160, in safe_indexing\n    return X.take(indices, axis=0)\nIndexError: index 1492 is out of bounds for size 155\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nIndexError                                         Wed Jul 11 10:49:27 2018\nPID: 4811               Python 3.6.5: /opt/anaconda/envs/Python3/bin/python\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (GridSearchCV(cv=ShuffleSplit(1940, n_iter=10, te...='2*n_jobs', refit=True, scoring=None, verbose=0), array([[364.,   2., 243., ...,   0.,   0.,   0.]...      [877.,   2., 101., ...,   0.,   0.,   0.]]), array([3.  , 3.  , 2.  , ..., 1.25, 1.75, 1.25]), <function _passthrough_scorer>, array([ 755,  597, 1098,  652,  698,   65, 1116,... 769,  724, 1210,   89,  413,  941,\n        697]), array([ 458,  247, 1333, 1902, 1922, 1052,  680,...1078,  894, 1485, 1599,\n        326, 1374,  963]), 0), {'error_score': 'raise', 'fit_params': None, 'parameters': None, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (GridSearchCV(cv=ShuffleSplit(1940, n_iter=10, te...='2*n_jobs', refit=True, scoring=None, verbose=0), array([[364.,   2., 243., ...,   0.,   0.,   0.]...      [877.,   2., 101., ...,   0.,   0.,   0.]]), array([3.  , 3.  , 2.  , ..., 1.25, 1.75, 1.25]), <function _passthrough_scorer>, array([ 755,  597, 1098,  652,  698,   65, 1116,... 769,  724, 1210,   89,  413,  941,\n        697]), array([ 458,  247, 1333, 1902, 1922, 1052,  680,...1078,  894, 1485, 1599,\n        326, 1374,  963]), 0)\n        kwargs = {'error_score': 'raise', 'fit_params': None, 'parameters': None, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/cross_validation.py in _fit_and_score(estimator=GridSearchCV(cv=ShuffleSplit(1940, n_iter=10, te...='2*n_jobs', refit=True, scoring=None, verbose=0), X=array([[364.,   2., 243., ...,   0.,   0.,   0.]...      [877.,   2., 101., ...,   0.,   0.,   0.]]), y=array([3.  , 3.  , 2.  , ..., 1.25, 1.75, 1.25]), scorer=<function _passthrough_scorer>, train=array([ 755,  597, 1098,  652,  698,   65, 1116,... 769,  724, 1210,   89,  413,  941,\n        697]), test=array([ 458,  247, 1333, 1902, 1922, 1052,  680,...1078,  894, 1485, 1599,\n        326, 1374,  963]), verbose=0, parameters=None, fit_params={}, return_train_score=True, return_parameters=False, error_score='raise')\n   1670 \n   1671     try:\n   1672         if y_train is None:\n   1673             estimator.fit(X_train, **fit_params)\n   1674         else:\n-> 1675             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method GridSearchCV.fit of GridSearchCV(c...'2*n_jobs', refit=True, scoring=None, verbose=0)>\n        X_train = array([[4.480e+02, 2.000e+00, 6.000e+01, ..., 0...., ..., 0.000e+00, 0.000e+00,\n        0.000e+00]])\n        y_train = array([2.33, 2.67, 1.  , 1.33, 2.67, 1.  , 2.  ,...1.33, 2.33, 2.75, 1.67, 1.25, 1.67,\n       2.33])\n        fit_params = {}\n   1676 \n   1677     except Exception as e:\n   1678         if error_score == 'raise':\n   1679             raise\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/grid_search.py in fit(self=GridSearchCV(cv=ShuffleSplit(1940, n_iter=10, te...='2*n_jobs', refit=True, scoring=None, verbose=0), X=array([[4.480e+02, 2.000e+00, 6.000e+01, ..., 0...., ..., 0.000e+00, 0.000e+00,\n        0.000e+00]]), y=array([2.33, 2.67, 1.  , 1.33, 2.67, 1.  , 2.  ,...1.33, 2.33, 2.75, 1.67, 1.25, 1.67,\n       2.33]))\n    833         y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n    834             Target relative to X for classification or regression;\n    835             None for unsupervised learning.\n    836 \n    837         \"\"\"\n--> 838         return self._fit(X, y, ParameterGrid(self.param_grid))\n        self._fit = <bound method BaseSearchCV._fit of GridSearchCV(...'2*n_jobs', refit=True, scoring=None, verbose=0)>\n        X = array([[4.480e+02, 2.000e+00, 6.000e+01, ..., 0...., ..., 0.000e+00, 0.000e+00,\n        0.000e+00]])\n        y = array([2.33, 2.67, 1.  , 1.33, 2.67, 1.  , 2.  ,...1.33, 2.33, 2.75, 1.67, 1.25, 1.67,\n       2.33])\n        self.param_grid = {'learning_rate': [0.05, 0.02], 'max_depth': [9, 12], 'max_features': [0.3, 0.4], 'min_samples_leaf': [18, 20, 22], 'n_estimators': [25, 50, 250]}\n    839 \n    840 \n    841 class RandomizedSearchCV(BaseSearchCV):\n    842     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/grid_search.py in _fit(self=GridSearchCV(cv=ShuffleSplit(1940, n_iter=10, te...='2*n_jobs', refit=True, scoring=None, verbose=0), X=array([[4.480e+02, 2.000e+00, 6.000e+01, ..., 0...., ..., 0.000e+00, 0.000e+00,\n        0.000e+00]]), y=array([2.33, 2.67, 1.  , 1.33, 2.67, 1.  , 2.  ,...1.33, 2.33, 2.75, 1.67, 1.25, 1.67,\n       2.33]), parameter_iterable=<sklearn.grid_search.ParameterGrid object>)\n    569         )(\n    570             delayed(_fit_and_score)(clone(base_estimator), X, y, self.scorer_,\n    571                                     train, test, self.verbose, parameters,\n    572                                     self.fit_params, return_parameters=True,\n    573                                     error_score=self.error_score)\n--> 574                 for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.grid_search.ParameterGrid object>\n    575                 for train, test in cv)\n    576 \n    577         # Out is a list of triplet: score, estimator, n_test_samples\n    578         n_fits = len(out)\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=4), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    774         self.n_completed_tasks = 0\n    775         try:\n    776             # Only set self._iterating to True if at least a batch\n    777             # was dispatched. In particular this covers the edge\n    778             # case of Parallel used with an exhausted iterator.\n--> 779             while self.dispatch_one_batch(iterator):\n        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=4)>\n        iterator = <generator object BaseSearchCV._fit.<locals>.<genexpr>>\n    780                 self._iterating = True\n    781             else:\n    782                 self._iterating = False\n    783 \n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=4), iterator=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    620             tasks = BatchedCalls(itertools.islice(iterator, batch_size))\n    621             if len(tasks) == 0:\n    622                 # No more tasks available in the iterator: tell caller to stop.\n    623                 return False\n    624             else:\n--> 625                 self._dispatch(tasks)\n        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=4)>\n        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    626                 return True\n    627 \n    628     def _print(self, msg, msg_args):\n    629         \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=4), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    583         self.n_dispatched_tasks += len(batch)\n    584         self.n_dispatched_batches += 1\n    585 \n    586         dispatch_timestamp = time.time()\n    587         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)\n--> 588         job = self._backend.apply_async(batch, callback=cb)\n        job = undefined\n        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>\n    589         self._jobs.append(job)\n    590 \n    591     def dispatch_next(self):\n    592         \"\"\"Dispatch more data for parallel processing\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)\n    106             raise ValueError('n_jobs == 0 in Parallel has no meaning')\n    107         return 1\n    108 \n    109     def apply_async(self, func, callback=None):\n    110         \"\"\"Schedule a func to be run\"\"\"\n--> 111         result = ImmediateResult(func)\n        result = undefined\n        func = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    112         if callback:\n    113             callback(result)\n    114         return result\n    115 \n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    327 \n    328 class ImmediateResult(object):\n    329     def __init__(self, batch):\n    330         # Don't delay the application, to avoid keeping the input\n    331         # arguments in memory\n--> 332         self.results = batch()\n        self.results = undefined\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    333 \n    334     def get(self):\n    335         return self.results\n    336 \n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (GradientBoostingRegressor(alpha=0.9, criterion='...      subsample=1.0, verbose=0, warm_start=False), array([[4.480e+02, 2.000e+00, 6.000e+01, ..., 0...., ..., 0.000e+00, 0.000e+00,\n        0.000e+00]]), array([2.33, 2.67, 1.  , 1.33, 2.67, 1.  , 2.  ,...1.33, 2.33, 2.75, 1.67, 1.25, 1.67,\n       2.33]), <function _passthrough_scorer>, array([ 134, 1492,  891, ..., 1777,  323, 1307]), array([1054,  714, 1056,  342, 1085,  782,   17,... 774, 1539, 1057,  282,\n       1494, 1031,  525]), 0, {'learning_rate': 0.05, 'max_depth': 9, 'max_features': 0.3, 'min_samples_leaf': 18, 'n_estimators': 25}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (GradientBoostingRegressor(alpha=0.9, criterion='...      subsample=1.0, verbose=0, warm_start=False), array([[4.480e+02, 2.000e+00, 6.000e+01, ..., 0...., ..., 0.000e+00, 0.000e+00,\n        0.000e+00]]), array([2.33, 2.67, 1.  , 1.33, 2.67, 1.  , 2.  ,...1.33, 2.33, 2.75, 1.67, 1.25, 1.67,\n       2.33]), <function _passthrough_scorer>, array([ 134, 1492,  891, ..., 1777,  323, 1307]), array([1054,  714, 1056,  342, 1085,  782,   17,... 774, 1539, 1057,  282,\n       1494, 1031,  525]), 0, {'learning_rate': 0.05, 'max_depth': 9, 'max_features': 0.3, 'min_samples_leaf': 18, 'n_estimators': 25}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/cross_validation.py in _fit_and_score(estimator=GradientBoostingRegressor(alpha=0.9, criterion='...      subsample=1.0, verbose=0, warm_start=False), X=array([[4.480e+02, 2.000e+00, 6.000e+01, ..., 0...., ..., 0.000e+00, 0.000e+00,\n        0.000e+00]]), y=array([2.33, 2.67, 1.  , 1.33, 2.67, 1.  , 2.  ,...1.33, 2.33, 2.75, 1.67, 1.25, 1.67,\n       2.33]), scorer=<function _passthrough_scorer>, train=array([ 134, 1492,  891, ..., 1777,  323, 1307]), test=array([1054,  714, 1056,  342, 1085,  782,   17,... 774, 1539, 1057,  282,\n       1494, 1031,  525]), verbose=0, parameters={'learning_rate': 0.05, 'max_depth': 9, 'max_features': 0.3, 'min_samples_leaf': 18, 'n_estimators': 25}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1663     if parameters is not None:\n   1664         estimator.set_params(**parameters)\n   1665 \n   1666     start_time = time.time()\n   1667 \n-> 1668     X_train, y_train = _safe_split(estimator, X, y, train)\n        X_train = undefined\n        y_train = undefined\n        estimator = GradientBoostingRegressor(alpha=0.9, criterion='...      subsample=1.0, verbose=0, warm_start=False)\n        X = array([[4.480e+02, 2.000e+00, 6.000e+01, ..., 0...., ..., 0.000e+00, 0.000e+00,\n        0.000e+00]])\n        y = array([2.33, 2.67, 1.  , 1.33, 2.67, 1.  , 2.  ,...1.33, 2.33, 2.75, 1.67, 1.25, 1.67,\n       2.33])\n        train = array([ 134, 1492,  891, ..., 1777,  323, 1307])\n   1669     X_test, y_test = _safe_split(estimator, X, y, test, train)\n   1670 \n   1671     try:\n   1672         if y_train is None:\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/cross_validation.py in _safe_split(estimator=GradientBoostingRegressor(alpha=0.9, criterion='...      subsample=1.0, verbose=0, warm_start=False), X=array([[4.480e+02, 2.000e+00, 6.000e+01, ..., 0...., ..., 0.000e+00, 0.000e+00,\n        0.000e+00]]), y=array([2.33, 2.67, 1.  , 1.33, 2.67, 1.  , 2.  ,...1.33, 2.33, 2.75, 1.67, 1.25, 1.67,\n       2.33]), indices=array([ 134, 1492,  891, ..., 1777,  323, 1307]), train_indices=None)\n   1731             if train_indices is None:\n   1732                 X_subset = X[np.ix_(indices, indices)]\n   1733             else:\n   1734                 X_subset = X[np.ix_(indices, train_indices)]\n   1735         else:\n-> 1736             X_subset = safe_indexing(X, indices)\n        X_subset = undefined\n        X = array([[4.480e+02, 2.000e+00, 6.000e+01, ..., 0...., ..., 0.000e+00, 0.000e+00,\n        0.000e+00]])\n        indices = array([ 134, 1492,  891, ..., 1777,  323, 1307])\n   1737 \n   1738     if y is not None:\n   1739         y_subset = safe_indexing(y, indices)\n   1740     else:\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/utils/__init__.py in safe_indexing(X=array([[4.480e+02, 2.000e+00, 6.000e+01, ..., 0...., ..., 0.000e+00, 0.000e+00,\n        0.000e+00]]), indices=array([ 134, 1492,  891, ..., 1777,  323, 1307]))\n    155             return X.copy().iloc[indices]\n    156     elif hasattr(X, \"shape\"):\n    157         if hasattr(X, 'take') and (hasattr(indices, 'dtype') and\n    158                                    indices.dtype.kind == 'i'):\n    159             # This is often substantially faster than X[indices]\n--> 160             return X.take(indices, axis=0)\n        X.take = <built-in method take of numpy.ndarray object>\n        indices = array([ 134, 1492,  891, ..., 1777,  323, 1307])\n    161         else:\n    162             return X[indices]\n    163     else:\n    164         return [X[idx] for idx in indices]\n\nIndexError: index 1492 is out of bounds for size 155\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/Python3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nIndexError                                         Wed Jul 11 10:49:27 2018\nPID: 4811               Python 3.6.5: /opt/anaconda/envs/Python3/bin/python\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (GridSearchCV(cv=ShuffleSplit(1940, n_iter=10, te...='2*n_jobs', refit=True, scoring=None, verbose=0), array([[364.,   2., 243., ...,   0.,   0.,   0.]...      [877.,   2., 101., ...,   0.,   0.,   0.]]), array([3.  , 3.  , 2.  , ..., 1.25, 1.75, 1.25]), <function _passthrough_scorer>, array([ 755,  597, 1098,  652,  698,   65, 1116,... 769,  724, 1210,   89,  413,  941,\n        697]), array([ 458,  247, 1333, 1902, 1922, 1052,  680,...1078,  894, 1485, 1599,\n        326, 1374,  963]), 0), {'error_score': 'raise', 'fit_params': None, 'parameters': None, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (GridSearchCV(cv=ShuffleSplit(1940, n_iter=10, te...='2*n_jobs', refit=True, scoring=None, verbose=0), array([[364.,   2., 243., ...,   0.,   0.,   0.]...      [877.,   2., 101., ...,   0.,   0.,   0.]]), array([3.  , 3.  , 2.  , ..., 1.25, 1.75, 1.25]), <function _passthrough_scorer>, array([ 755,  597, 1098,  652,  698,   65, 1116,... 769,  724, 1210,   89,  413,  941,\n        697]), array([ 458,  247, 1333, 1902, 1922, 1052,  680,...1078,  894, 1485, 1599,\n        326, 1374,  963]), 0)\n        kwargs = {'error_score': 'raise', 'fit_params': None, 'parameters': None, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/cross_validation.py in _fit_and_score(estimator=GridSearchCV(cv=ShuffleSplit(1940, n_iter=10, te...='2*n_jobs', refit=True, scoring=None, verbose=0), X=array([[364.,   2., 243., ...,   0.,   0.,   0.]...      [877.,   2., 101., ...,   0.,   0.,   0.]]), y=array([3.  , 3.  , 2.  , ..., 1.25, 1.75, 1.25]), scorer=<function _passthrough_scorer>, train=array([ 755,  597, 1098,  652,  698,   65, 1116,... 769,  724, 1210,   89,  413,  941,\n        697]), test=array([ 458,  247, 1333, 1902, 1922, 1052,  680,...1078,  894, 1485, 1599,\n        326, 1374,  963]), verbose=0, parameters=None, fit_params={}, return_train_score=True, return_parameters=False, error_score='raise')\n   1670 \n   1671     try:\n   1672         if y_train is None:\n   1673             estimator.fit(X_train, **fit_params)\n   1674         else:\n-> 1675             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method GridSearchCV.fit of GridSearchCV(c...'2*n_jobs', refit=True, scoring=None, verbose=0)>\n        X_train = array([[4.480e+02, 2.000e+00, 6.000e+01, ..., 0...., ..., 0.000e+00, 0.000e+00,\n        0.000e+00]])\n        y_train = array([2.33, 2.67, 1.  , 1.33, 2.67, 1.  , 2.  ,...1.33, 2.33, 2.75, 1.67, 1.25, 1.67,\n       2.33])\n        fit_params = {}\n   1676 \n   1677     except Exception as e:\n   1678         if error_score == 'raise':\n   1679             raise\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/grid_search.py in fit(self=GridSearchCV(cv=ShuffleSplit(1940, n_iter=10, te...='2*n_jobs', refit=True, scoring=None, verbose=0), X=array([[4.480e+02, 2.000e+00, 6.000e+01, ..., 0...., ..., 0.000e+00, 0.000e+00,\n        0.000e+00]]), y=array([2.33, 2.67, 1.  , 1.33, 2.67, 1.  , 2.  ,...1.33, 2.33, 2.75, 1.67, 1.25, 1.67,\n       2.33]))\n    833         y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n    834             Target relative to X for classification or regression;\n    835             None for unsupervised learning.\n    836 \n    837         \"\"\"\n--> 838         return self._fit(X, y, ParameterGrid(self.param_grid))\n        self._fit = <bound method BaseSearchCV._fit of GridSearchCV(...'2*n_jobs', refit=True, scoring=None, verbose=0)>\n        X = array([[4.480e+02, 2.000e+00, 6.000e+01, ..., 0...., ..., 0.000e+00, 0.000e+00,\n        0.000e+00]])\n        y = array([2.33, 2.67, 1.  , 1.33, 2.67, 1.  , 2.  ,...1.33, 2.33, 2.75, 1.67, 1.25, 1.67,\n       2.33])\n        self.param_grid = {'learning_rate': [0.05, 0.02], 'max_depth': [9, 12], 'max_features': [0.3, 0.4], 'min_samples_leaf': [18, 20, 22], 'n_estimators': [25, 50, 250]}\n    839 \n    840 \n    841 class RandomizedSearchCV(BaseSearchCV):\n    842     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/grid_search.py in _fit(self=GridSearchCV(cv=ShuffleSplit(1940, n_iter=10, te...='2*n_jobs', refit=True, scoring=None, verbose=0), X=array([[4.480e+02, 2.000e+00, 6.000e+01, ..., 0...., ..., 0.000e+00, 0.000e+00,\n        0.000e+00]]), y=array([2.33, 2.67, 1.  , 1.33, 2.67, 1.  , 2.  ,...1.33, 2.33, 2.75, 1.67, 1.25, 1.67,\n       2.33]), parameter_iterable=<sklearn.grid_search.ParameterGrid object>)\n    569         )(\n    570             delayed(_fit_and_score)(clone(base_estimator), X, y, self.scorer_,\n    571                                     train, test, self.verbose, parameters,\n    572                                     self.fit_params, return_parameters=True,\n    573                                     error_score=self.error_score)\n--> 574                 for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.grid_search.ParameterGrid object>\n    575                 for train, test in cv)\n    576 \n    577         # Out is a list of triplet: score, estimator, n_test_samples\n    578         n_fits = len(out)\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=4), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    774         self.n_completed_tasks = 0\n    775         try:\n    776             # Only set self._iterating to True if at least a batch\n    777             # was dispatched. In particular this covers the edge\n    778             # case of Parallel used with an exhausted iterator.\n--> 779             while self.dispatch_one_batch(iterator):\n        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=4)>\n        iterator = <generator object BaseSearchCV._fit.<locals>.<genexpr>>\n    780                 self._iterating = True\n    781             else:\n    782                 self._iterating = False\n    783 \n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=4), iterator=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    620             tasks = BatchedCalls(itertools.islice(iterator, batch_size))\n    621             if len(tasks) == 0:\n    622                 # No more tasks available in the iterator: tell caller to stop.\n    623                 return False\n    624             else:\n--> 625                 self._dispatch(tasks)\n        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=4)>\n        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    626                 return True\n    627 \n    628     def _print(self, msg, msg_args):\n    629         \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=4), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    583         self.n_dispatched_tasks += len(batch)\n    584         self.n_dispatched_batches += 1\n    585 \n    586         dispatch_timestamp = time.time()\n    587         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)\n--> 588         job = self._backend.apply_async(batch, callback=cb)\n        job = undefined\n        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>\n    589         self._jobs.append(job)\n    590 \n    591     def dispatch_next(self):\n    592         \"\"\"Dispatch more data for parallel processing\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)\n    106             raise ValueError('n_jobs == 0 in Parallel has no meaning')\n    107         return 1\n    108 \n    109     def apply_async(self, func, callback=None):\n    110         \"\"\"Schedule a func to be run\"\"\"\n--> 111         result = ImmediateResult(func)\n        result = undefined\n        func = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    112         if callback:\n    113             callback(result)\n    114         return result\n    115 \n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    327 \n    328 class ImmediateResult(object):\n    329     def __init__(self, batch):\n    330         # Don't delay the application, to avoid keeping the input\n    331         # arguments in memory\n--> 332         self.results = batch()\n        self.results = undefined\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    333 \n    334     def get(self):\n    335         return self.results\n    336 \n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (GradientBoostingRegressor(alpha=0.9, criterion='...      subsample=1.0, verbose=0, warm_start=False), array([[4.480e+02, 2.000e+00, 6.000e+01, ..., 0...., ..., 0.000e+00, 0.000e+00,\n        0.000e+00]]), array([2.33, 2.67, 1.  , 1.33, 2.67, 1.  , 2.  ,...1.33, 2.33, 2.75, 1.67, 1.25, 1.67,\n       2.33]), <function _passthrough_scorer>, array([ 134, 1492,  891, ..., 1777,  323, 1307]), array([1054,  714, 1056,  342, 1085,  782,   17,... 774, 1539, 1057,  282,\n       1494, 1031,  525]), 0, {'learning_rate': 0.05, 'max_depth': 9, 'max_features': 0.3, 'min_samples_leaf': 18, 'n_estimators': 25}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (GradientBoostingRegressor(alpha=0.9, criterion='...      subsample=1.0, verbose=0, warm_start=False), array([[4.480e+02, 2.000e+00, 6.000e+01, ..., 0...., ..., 0.000e+00, 0.000e+00,\n        0.000e+00]]), array([2.33, 2.67, 1.  , 1.33, 2.67, 1.  , 2.  ,...1.33, 2.33, 2.75, 1.67, 1.25, 1.67,\n       2.33]), <function _passthrough_scorer>, array([ 134, 1492,  891, ..., 1777,  323, 1307]), array([1054,  714, 1056,  342, 1085,  782,   17,... 774, 1539, 1057,  282,\n       1494, 1031,  525]), 0, {'learning_rate': 0.05, 'max_depth': 9, 'max_features': 0.3, 'min_samples_leaf': 18, 'n_estimators': 25}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/cross_validation.py in _fit_and_score(estimator=GradientBoostingRegressor(alpha=0.9, criterion='...      subsample=1.0, verbose=0, warm_start=False), X=array([[4.480e+02, 2.000e+00, 6.000e+01, ..., 0...., ..., 0.000e+00, 0.000e+00,\n        0.000e+00]]), y=array([2.33, 2.67, 1.  , 1.33, 2.67, 1.  , 2.  ,...1.33, 2.33, 2.75, 1.67, 1.25, 1.67,\n       2.33]), scorer=<function _passthrough_scorer>, train=array([ 134, 1492,  891, ..., 1777,  323, 1307]), test=array([1054,  714, 1056,  342, 1085,  782,   17,... 774, 1539, 1057,  282,\n       1494, 1031,  525]), verbose=0, parameters={'learning_rate': 0.05, 'max_depth': 9, 'max_features': 0.3, 'min_samples_leaf': 18, 'n_estimators': 25}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1663     if parameters is not None:\n   1664         estimator.set_params(**parameters)\n   1665 \n   1666     start_time = time.time()\n   1667 \n-> 1668     X_train, y_train = _safe_split(estimator, X, y, train)\n        X_train = undefined\n        y_train = undefined\n        estimator = GradientBoostingRegressor(alpha=0.9, criterion='...      subsample=1.0, verbose=0, warm_start=False)\n        X = array([[4.480e+02, 2.000e+00, 6.000e+01, ..., 0...., ..., 0.000e+00, 0.000e+00,\n        0.000e+00]])\n        y = array([2.33, 2.67, 1.  , 1.33, 2.67, 1.  , 2.  ,...1.33, 2.33, 2.75, 1.67, 1.25, 1.67,\n       2.33])\n        train = array([ 134, 1492,  891, ..., 1777,  323, 1307])\n   1669     X_test, y_test = _safe_split(estimator, X, y, test, train)\n   1670 \n   1671     try:\n   1672         if y_train is None:\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/cross_validation.py in _safe_split(estimator=GradientBoostingRegressor(alpha=0.9, criterion='...      subsample=1.0, verbose=0, warm_start=False), X=array([[4.480e+02, 2.000e+00, 6.000e+01, ..., 0...., ..., 0.000e+00, 0.000e+00,\n        0.000e+00]]), y=array([2.33, 2.67, 1.  , 1.33, 2.67, 1.  , 2.  ,...1.33, 2.33, 2.75, 1.67, 1.25, 1.67,\n       2.33]), indices=array([ 134, 1492,  891, ..., 1777,  323, 1307]), train_indices=None)\n   1731             if train_indices is None:\n   1732                 X_subset = X[np.ix_(indices, indices)]\n   1733             else:\n   1734                 X_subset = X[np.ix_(indices, train_indices)]\n   1735         else:\n-> 1736             X_subset = safe_indexing(X, indices)\n        X_subset = undefined\n        X = array([[4.480e+02, 2.000e+00, 6.000e+01, ..., 0...., ..., 0.000e+00, 0.000e+00,\n        0.000e+00]])\n        indices = array([ 134, 1492,  891, ..., 1777,  323, 1307])\n   1737 \n   1738     if y is not None:\n   1739         y_subset = safe_indexing(y, indices)\n   1740     else:\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/utils/__init__.py in safe_indexing(X=array([[4.480e+02, 2.000e+00, 6.000e+01, ..., 0...., ..., 0.000e+00, 0.000e+00,\n        0.000e+00]]), indices=array([ 134, 1492,  891, ..., 1777,  323, 1307]))\n    155             return X.copy().iloc[indices]\n    156     elif hasattr(X, \"shape\"):\n    157         if hasattr(X, 'take') and (hasattr(indices, 'dtype') and\n    158                                    indices.dtype.kind == 'i'):\n    159             # This is often substantially faster than X[indices]\n--> 160             return X.take(indices, axis=0)\n        X.take = <built-in method take of numpy.ndarray object>\n        indices = array([ 134, 1492,  891, ..., 1777,  323, 1307])\n    161         else:\n    162             return X[indices]\n    163     else:\n    164         return [X[idx] for idx in indices]\n\nIndexError: index 1492 is out of bounds for size 155\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibIndexError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-a2a084748d3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m                                       \u001b[0mmin_samples_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbest_est\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_samples_leaf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                                       max_features=best_est.max_features) \n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mplot_learning_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-843abeac6091>\u001b[0m in \u001b[0;36mplot_learning_curve\u001b[0;34m(estimator, title, X, y, ylim, cv, n_jobs, train_sizes)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training examples\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtrain_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearning_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_sizes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mtrain_scores_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mtrain_scores_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/learning_curve.py\u001b[0m in \u001b[0;36mlearning_curve\u001b[0;34m(estimator, X, y, train_sizes, cv, scoring, exploit_incremental_learning, n_jobs, pre_dispatch, verbose, error_score)\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 171\u001b[0;31m             for train, test in cv for n_train_samples in train_sizes_abs)\n\u001b[0m\u001b[1;32m    172\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mn_cv_folds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mn_unique_ticks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibIndexError\u001b[0m: JoblibIndexError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.6/site-packages/ipykernel/__main__.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x7f7a8f2b26f0, file \"/...3.6/site-packages/ipykernel/__main__.py\", line 1>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/opt/anaconda/envs/Python3/lib/python3.6/site-packages/ipykernel/__pycache__/__main__.cpython-36.pyc', '__doc__': None, '__file__': '/opt/anaconda/envs/Python3/lib/python3.6/site-packages/ipykernel/__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.6/site-packages/ipykernel/__main__.py'), 'app': <module 'ipykernel.kernelapp' from '/opt/anacond.../python3.6/site-packages/ipykernel/kernelapp.py'>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.6/site-packages/ipykernel/__main__.py'), pkg_name='ipykernel', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7f7a8f2b26f0, file \"/...3.6/site-packages/ipykernel/__main__.py\", line 1>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/opt/anaconda/envs/Python3/lib/python3.6/site-packages/ipykernel/__pycache__/__main__.cpython-36.pyc', '__doc__': None, '__file__': '/opt/anaconda/envs/Python3/lib/python3.6/site-packages/ipykernel/__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.6/site-packages/ipykernel/__main__.py'), 'app': <module 'ipykernel.kernelapp' from '/opt/anacond.../python3.6/site-packages/ipykernel/kernelapp.py'>}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/ipykernel/__main__.py in <module>()\n      1 if __name__ == '__main__':\n      2     from ipykernel import kernelapp as app\n----> 3     app.launch_new_instance()\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/tornado/platform/asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    122         except (RuntimeError, AssertionError):\n    123             old_loop = None\n    124         try:\n    125             self._setup_logging()\n    126             asyncio.set_event_loop(self.asyncio_loop)\n--> 127             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Uni...EventLoop running=True closed=False debug=False>>\n    128         finally:\n    129             asyncio.set_event_loop(old_loop)\n    130 \n    131     def stop(self):\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/asyncio/base_events.py in run_forever(self=<_UnixSelectorEventLoop running=True closed=False debug=False>)\n    417             sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    418                                    finalizer=self._asyncgen_finalizer_hook)\n    419         try:\n    420             events._set_running_loop(self)\n    421             while True:\n--> 422                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_UnixS...EventLoop running=True closed=False debug=False>>\n    423                 if self._stopping:\n    424                     break\n    425         finally:\n    426             self._stopping = False\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/asyncio/base_events.py in _run_once(self=<_UnixSelectorEventLoop running=True closed=False debug=False>)\n   1427                         logger.warning('Executing %s took %.3f seconds',\n   1428                                        _format_handle(handle), dt)\n   1429                 finally:\n   1430                     self._current_handle = None\n   1431             else:\n-> 1432                 handle._run()\n        handle._run = <bound method Handle._run of <Handle BaseAsyncIOLoop._handle_events(11, 1)>>\n   1433         handle = None  # Needed to break cycles when an exception occurs.\n   1434 \n   1435     def _set_coroutine_wrapper(self, enabled):\n   1436         try:\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/asyncio/events.py in _run(self=<Handle BaseAsyncIOLoop._handle_events(11, 1)>)\n    140             self._callback = None\n    141             self._args = None\n    142 \n    143     def _run(self):\n    144         try:\n--> 145             self._callback(*self._args)\n        self._callback = <bound method BaseAsyncIOLoop._handle_events of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (11, 1)\n    146         except Exception as exc:\n    147             cb = _format_callback_source(self._callback, self._args)\n    148             msg = 'Exception in callback {}'.format(cb)\n    149             context = {\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/tornado/platform/asyncio.py in _handle_events(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, fd=11, events=1)\n    112             self.writers.remove(fd)\n    113         del self.handlers[fd]\n    114 \n    115     def _handle_events(self, fd, events):\n    116         fileobj, handler_func = self.handlers[fd]\n--> 117         handler_func(fileobj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fileobj = <zmq.sugar.socket.Socket object>\n        events = 1\n    118 \n    119     def start(self):\n    120         try:\n    121             old_loop = asyncio.get_event_loop()\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"#OK we'll now call the plot_learning_curve modul...g rate even further to address any overfitting. \\n\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 7, 11, 10, 49, 27, 669785, tzinfo=tzlocal()), 'msg_id': '1cfb2f6ff68f419e80b9c9c74ac650c8', 'msg_type': 'execute_request', 'session': '18d55d334c6240f98c2713286b64cdb2', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '1cfb2f6ff68f419e80b9c9c74ac650c8', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'18d55d334c6240f98c2713286b64cdb2']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"#OK we'll now call the plot_learning_curve modul...g rate even further to address any overfitting. \\n\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 7, 11, 10, 49, 27, 669785, tzinfo=tzlocal()), 'msg_id': '1cfb2f6ff68f419e80b9c9c74ac650c8', 'msg_type': 'execute_request', 'session': '18d55d334c6240f98c2713286b64cdb2', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '1cfb2f6ff68f419e80b9c9c74ac650c8', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'18d55d334c6240f98c2713286b64cdb2'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"#OK we'll now call the plot_learning_curve modul...g rate even further to address any overfitting. \\n\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 7, 11, 10, 49, 27, 669785, tzinfo=tzlocal()), 'msg_id': '1cfb2f6ff68f419e80b9c9c74ac650c8', 'msg_type': 'execute_request', 'session': '18d55d334c6240f98c2713286b64cdb2', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '1cfb2f6ff68f419e80b9c9c74ac650c8', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"#OK we'll now call the plot_learning_curve modul...g rate even further to address any overfitting. \\n\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"#OK we'll now call the plot_learning_curve modul...g rate even further to address any overfitting. \\n\"\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"#OK we'll now call the plot_learning_curve modul...g rate even further to address any overfitting. \\n\",), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"#OK we'll now call the plot_learning_curve modul...g rate even further to address any overfitting. \\n\",)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"#OK we'll now call the plot_learning_curve modul...g rate even further to address any overfitting. \\n\", store_history=True, silent=False, shell_futures=True)\n   2657         -------\n   2658         result : :class:`ExecutionResult`\n   2659         \"\"\"\n   2660         try:\n   2661             result = self._run_cell(\n-> 2662                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = \"#OK we'll now call the plot_learning_curve modul...g rate even further to address any overfitting. \\n\"\n        store_history = True\n        silent = False\n        shell_futures = True\n   2663         finally:\n   2664             self.events.trigger('post_execute')\n   2665             if not silent:\n   2666                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"#OK we'll now call the plot_learning_curve modul...g rate even further to address any overfitting. \\n\", store_history=True, silent=False, shell_futures=True)\n   2780                 self.displayhook.exec_result = result\n   2781 \n   2782                 # Execute the user code\n   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2786                 \n   2787                 self.last_execution_succeeded = not has_raised\n   2788                 self.last_execution_result = result\n   2789 \n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Expr object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>], cell_name='<ipython-input-30-a2a084748d3a>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7f7a52cdb240, executi...rue silent=False shell_futures=True> result=None>)\n   2898 \n   2899         try:\n   2900             for i, node in enumerate(to_run_exec):\n   2901                 mod = ast.Module([node])\n   2902                 code = compiler(mod, cell_name, \"exec\")\n-> 2903                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f7a51e98270, file \"<ipython-input-30-a2a084748d3a>\", line 14>\n        result = <ExecutionResult object at 7f7a52cdb240, executi...rue silent=False shell_futures=True> result=None>\n   2904                     return True\n   2905 \n   2906             for i, node in enumerate(to_run_interactive):\n   2907                 mod = ast.Interactive([node])\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f7a51e98270, file \"<ipython-input-30-a2a084748d3a>\", line 14>, result=<ExecutionResult object at 7f7a52cdb240, executi...rue silent=False shell_futures=True> result=None>)\n   2958         outflag = True  # happens in more places, so it's easier as default\n   2959         try:\n   2960             try:\n   2961                 self.hooks.pre_run_code_hook()\n   2962                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2963                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f7a51e98270, file \"<ipython-input-30-a2a084748d3a>\", line 14>\n        self.user_global_ns = {'DatasetDexter': <class 'sellibrary.sel.dexter_dataset.DatasetDexter'>, 'ExtraTreesRegressor': <class 'sklearn.ensemble.forest.ExtraTreesRegressor'>, 'FileLocations': <class 'sellibrary.locations.FileLocations'>, 'FilterGolden': <class 'sellibrary.filter_only_golden.FilterGolden'>, 'GBRTWrapper': <class 'sellibrary.gbrt.GBRTWrapper'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, 'GradientBooster': <function GradientBooster>, 'GradientBoostingRegressor': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>, 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'INTERMEDIATE_PATH': '/project/Dropbox/Datasets/intermediate/', ...}\n        self.user_ns = {'DatasetDexter': <class 'sellibrary.sel.dexter_dataset.DatasetDexter'>, 'ExtraTreesRegressor': <class 'sklearn.ensemble.forest.ExtraTreesRegressor'>, 'FileLocations': <class 'sellibrary.locations.FileLocations'>, 'FilterGolden': <class 'sellibrary.filter_only_golden.FilterGolden'>, 'GBRTWrapper': <class 'sellibrary.gbrt.GBRTWrapper'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, 'GradientBooster': <function GradientBooster>, 'GradientBoostingRegressor': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>, 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'INTERMEDIATE_PATH': '/project/Dropbox/Datasets/intermediate/', ...}\n   2964             finally:\n   2965                 # Reset our crash handler in place\n   2966                 sys.excepthook = old_excepthook\n   2967         except SystemExit as e:\n\n...........................................................................\n/project/TX-Jupiter-Notebooks/UCL_COMPGB99/<ipython-input-30-a2a084748d3a> in <module>()\n      9 gbr_estimator = GradientBoostingRegressor(n_estimators=best_est.n_estimators, \n     10                                       max_depth=best_est.max_depth, \n     11                                       learning_rate=best_est.learning_rate, \n     12                                       min_samples_leaf=best_est.min_samples_leaf, \n     13                                       max_features=best_est.max_features) \n---> 14 plot_learning_curve(trained_model, title, X, y, cv=cv, n_jobs=n_jobs) \n     15 \n     16 plt.show() \n     17 logger.info('complete')\n     18 \n\n...........................................................................\n/project/TX-Jupiter-Notebooks/UCL_COMPGB99/<ipython-input-23-843abeac6091> in plot_learning_curve(estimator=GridSearchCV(cv=ShuffleSplit(1940, n_iter=10, te...='2*n_jobs', refit=True, scoring=None, verbose=0), title='Learning Curves (Gradient Boosted Regression Trees)', X=array([[364.,   2., 243., ...,   0.,   0.,   0.]...      [877.,   2., 101., ...,   0.,   0.,   0.]]), y=array([3.  , 3.  , 2.  , ..., 1.25, 1.75, 1.25]), ylim=None, cv=ShuffleSplit(1940, n_iter=10, test_size=0.2, random_state=None), n_jobs=4, train_sizes=array([0.1  , 0.325, 0.55 , 0.775, 1.   ]))\n     12     plt.figure()\n     13     plt.title(title)\n     14     if ylim is not None: plt.ylim(*ylim)\n     15     plt.xlabel(\"Training examples\")\n     16     plt.ylabel(\"Score\")\n---> 17     train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n     18     train_scores_mean = np.mean(train_scores, axis=1)\n     19     train_scores_std = np.std(train_scores, axis=1)\n     20     test_scores_mean = np.mean(test_scores, axis=1)\n     21     test_scores_std = np.std(test_scores, axis=1)\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/learning_curve.py in learning_curve(estimator=GridSearchCV(cv=ShuffleSplit(1940, n_iter=10, te...='2*n_jobs', refit=True, scoring=None, verbose=0), X=array([[364.,   2., 243., ...,   0.,   0.,   0.]...      [877.,   2., 101., ...,   0.,   0.,   0.]]), y=array([3.  , 3.  , 2.  , ..., 1.25, 1.75, 1.25]), train_sizes=array([0.1  , 0.325, 0.55 , 0.775, 1.   ]), cv=[(array([ 755,  597, 1098, ...,  909,  190,  295]), array([ 458,  247, 1333, 1902, 1922, 1052,  680,...1078,  894, 1485, 1599,\n        326, 1374,  963])), (array([1305, 1038,   12, ...,  199,  552,  414]), array([  86,  104, 1355,  977,  961, 1705, 1749,...1930,  513,  177, 1686,\n        387,  746,  992])), (array([1861,  713,  212, ...,  224, 1028, 1781]), array([ 125,  540, 1935,  199,  375,   11,  980,...1247,  956, 1541, 1489,\n        767,    5, 1246])), (array([1090, 1684,  882, ..., 1688, 1121, 1829]), array([1155,  947,  819,  125, 1621, 1740,  746,... 167, 1324, 1868,   97,\n        897,  109, 1400])), (array([1884,  429,  785, ..., 1437,  231, 1915]), array([ 660,  963, 1116,    0,  652,  607, 1193,... 520,  152, 1611,  813,\n        788, 1908, 1282])), (array([ 655,  292,  835, ..., 1481,  465,  437]), array([ 308, 1657,  746,   33, 1017, 1329, 1328,... 457,  276, 1656, 1936,\n       1349,  217, 1798])), (array([ 304, 1432,   76, ..., 1345,  640,  705]), array([ 268,   22, 1214, 1436, 1128,  122,  180,...1512,  729, 1548, 1392,\n        772, 1258, 1866])), (array([1778, 1342,   57, ..., 1508, 1618,   18]), array([ 280, 1519,  382, 1813, 1302,  801,  212,...1538, 1445, 1368,   21,\n         96,  262,  825])), (array([1678, 1604,  201, ...,  813, 1411,  423]), array([1546,  386,  928, 1331,  200,  133,  322,...1671, 1284, 1237,  564,\n        772, 1279, 1082])), (array([ 803, 1749, 1576, ..., 1342, 1819, 1438]), array([1456,  250,  307,  677, 1555, 1453,  299,...1081,  669,  604,  447,\n        214, 1296, 1233]))], scoring=None, exploit_incremental_learning=False, n_jobs=4, pre_dispatch='all', verbose=0, error_score='raise')\n    166     else:\n    167         out = parallel(delayed(_fit_and_score)(\n    168             clone(estimator), X, y, scorer, train[:n_train_samples], test,\n    169             verbose, parameters=None, fit_params=None, return_train_score=True,\n    170             error_score=error_score)\n--> 171             for train, test in cv for n_train_samples in train_sizes_abs)\n        cv = [(array([ 755,  597, 1098, ...,  909,  190,  295]), array([ 458,  247, 1333, 1902, 1922, 1052,  680,...1078,  894, 1485, 1599,\n        326, 1374,  963])), (array([1305, 1038,   12, ...,  199,  552,  414]), array([  86,  104, 1355,  977,  961, 1705, 1749,...1930,  513,  177, 1686,\n        387,  746,  992])), (array([1861,  713,  212, ...,  224, 1028, 1781]), array([ 125,  540, 1935,  199,  375,   11,  980,...1247,  956, 1541, 1489,\n        767,    5, 1246])), (array([1090, 1684,  882, ..., 1688, 1121, 1829]), array([1155,  947,  819,  125, 1621, 1740,  746,... 167, 1324, 1868,   97,\n        897,  109, 1400])), (array([1884,  429,  785, ..., 1437,  231, 1915]), array([ 660,  963, 1116,    0,  652,  607, 1193,... 520,  152, 1611,  813,\n        788, 1908, 1282])), (array([ 655,  292,  835, ..., 1481,  465,  437]), array([ 308, 1657,  746,   33, 1017, 1329, 1328,... 457,  276, 1656, 1936,\n       1349,  217, 1798])), (array([ 304, 1432,   76, ..., 1345,  640,  705]), array([ 268,   22, 1214, 1436, 1128,  122,  180,...1512,  729, 1548, 1392,\n        772, 1258, 1866])), (array([1778, 1342,   57, ..., 1508, 1618,   18]), array([ 280, 1519,  382, 1813, 1302,  801,  212,...1538, 1445, 1368,   21,\n         96,  262,  825])), (array([1678, 1604,  201, ...,  813, 1411,  423]), array([1546,  386,  928, 1331,  200,  133,  322,...1671, 1284, 1237,  564,\n        772, 1279, 1082])), (array([ 803, 1749, 1576, ..., 1342, 1819, 1438]), array([1456,  250,  307,  677, 1555, 1453,  299,...1081,  669,  604,  447,\n        214, 1296, 1233]))]\n    172         out = np.array(out)[:, :2]\n    173         n_cv_folds = out.shape[0] // n_unique_ticks\n    174         out = out.reshape(n_cv_folds, n_unique_ticks, 2)\n    175 \n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=4), iterable=<generator object learning_curve.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=4)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nIndexError                                         Wed Jul 11 10:49:27 2018\nPID: 4811               Python 3.6.5: /opt/anaconda/envs/Python3/bin/python\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (GridSearchCV(cv=ShuffleSplit(1940, n_iter=10, te...='2*n_jobs', refit=True, scoring=None, verbose=0), array([[364.,   2., 243., ...,   0.,   0.,   0.]...      [877.,   2., 101., ...,   0.,   0.,   0.]]), array([3.  , 3.  , 2.  , ..., 1.25, 1.75, 1.25]), <function _passthrough_scorer>, array([ 755,  597, 1098,  652,  698,   65, 1116,... 769,  724, 1210,   89,  413,  941,\n        697]), array([ 458,  247, 1333, 1902, 1922, 1052,  680,...1078,  894, 1485, 1599,\n        326, 1374,  963]), 0), {'error_score': 'raise', 'fit_params': None, 'parameters': None, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (GridSearchCV(cv=ShuffleSplit(1940, n_iter=10, te...='2*n_jobs', refit=True, scoring=None, verbose=0), array([[364.,   2., 243., ...,   0.,   0.,   0.]...      [877.,   2., 101., ...,   0.,   0.,   0.]]), array([3.  , 3.  , 2.  , ..., 1.25, 1.75, 1.25]), <function _passthrough_scorer>, array([ 755,  597, 1098,  652,  698,   65, 1116,... 769,  724, 1210,   89,  413,  941,\n        697]), array([ 458,  247, 1333, 1902, 1922, 1052,  680,...1078,  894, 1485, 1599,\n        326, 1374,  963]), 0)\n        kwargs = {'error_score': 'raise', 'fit_params': None, 'parameters': None, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/cross_validation.py in _fit_and_score(estimator=GridSearchCV(cv=ShuffleSplit(1940, n_iter=10, te...='2*n_jobs', refit=True, scoring=None, verbose=0), X=array([[364.,   2., 243., ...,   0.,   0.,   0.]...      [877.,   2., 101., ...,   0.,   0.,   0.]]), y=array([3.  , 3.  , 2.  , ..., 1.25, 1.75, 1.25]), scorer=<function _passthrough_scorer>, train=array([ 755,  597, 1098,  652,  698,   65, 1116,... 769,  724, 1210,   89,  413,  941,\n        697]), test=array([ 458,  247, 1333, 1902, 1922, 1052,  680,...1078,  894, 1485, 1599,\n        326, 1374,  963]), verbose=0, parameters=None, fit_params={}, return_train_score=True, return_parameters=False, error_score='raise')\n   1670 \n   1671     try:\n   1672         if y_train is None:\n   1673             estimator.fit(X_train, **fit_params)\n   1674         else:\n-> 1675             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method GridSearchCV.fit of GridSearchCV(c...'2*n_jobs', refit=True, scoring=None, verbose=0)>\n        X_train = array([[4.480e+02, 2.000e+00, 6.000e+01, ..., 0...., ..., 0.000e+00, 0.000e+00,\n        0.000e+00]])\n        y_train = array([2.33, 2.67, 1.  , 1.33, 2.67, 1.  , 2.  ,...1.33, 2.33, 2.75, 1.67, 1.25, 1.67,\n       2.33])\n        fit_params = {}\n   1676 \n   1677     except Exception as e:\n   1678         if error_score == 'raise':\n   1679             raise\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/grid_search.py in fit(self=GridSearchCV(cv=ShuffleSplit(1940, n_iter=10, te...='2*n_jobs', refit=True, scoring=None, verbose=0), X=array([[4.480e+02, 2.000e+00, 6.000e+01, ..., 0...., ..., 0.000e+00, 0.000e+00,\n        0.000e+00]]), y=array([2.33, 2.67, 1.  , 1.33, 2.67, 1.  , 2.  ,...1.33, 2.33, 2.75, 1.67, 1.25, 1.67,\n       2.33]))\n    833         y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n    834             Target relative to X for classification or regression;\n    835             None for unsupervised learning.\n    836 \n    837         \"\"\"\n--> 838         return self._fit(X, y, ParameterGrid(self.param_grid))\n        self._fit = <bound method BaseSearchCV._fit of GridSearchCV(...'2*n_jobs', refit=True, scoring=None, verbose=0)>\n        X = array([[4.480e+02, 2.000e+00, 6.000e+01, ..., 0...., ..., 0.000e+00, 0.000e+00,\n        0.000e+00]])\n        y = array([2.33, 2.67, 1.  , 1.33, 2.67, 1.  , 2.  ,...1.33, 2.33, 2.75, 1.67, 1.25, 1.67,\n       2.33])\n        self.param_grid = {'learning_rate': [0.05, 0.02], 'max_depth': [9, 12], 'max_features': [0.3, 0.4], 'min_samples_leaf': [18, 20, 22], 'n_estimators': [25, 50, 250]}\n    839 \n    840 \n    841 class RandomizedSearchCV(BaseSearchCV):\n    842     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/grid_search.py in _fit(self=GridSearchCV(cv=ShuffleSplit(1940, n_iter=10, te...='2*n_jobs', refit=True, scoring=None, verbose=0), X=array([[4.480e+02, 2.000e+00, 6.000e+01, ..., 0...., ..., 0.000e+00, 0.000e+00,\n        0.000e+00]]), y=array([2.33, 2.67, 1.  , 1.33, 2.67, 1.  , 2.  ,...1.33, 2.33, 2.75, 1.67, 1.25, 1.67,\n       2.33]), parameter_iterable=<sklearn.grid_search.ParameterGrid object>)\n    569         )(\n    570             delayed(_fit_and_score)(clone(base_estimator), X, y, self.scorer_,\n    571                                     train, test, self.verbose, parameters,\n    572                                     self.fit_params, return_parameters=True,\n    573                                     error_score=self.error_score)\n--> 574                 for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.grid_search.ParameterGrid object>\n    575                 for train, test in cv)\n    576 \n    577         # Out is a list of triplet: score, estimator, n_test_samples\n    578         n_fits = len(out)\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=4), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    774         self.n_completed_tasks = 0\n    775         try:\n    776             # Only set self._iterating to True if at least a batch\n    777             # was dispatched. In particular this covers the edge\n    778             # case of Parallel used with an exhausted iterator.\n--> 779             while self.dispatch_one_batch(iterator):\n        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=4)>\n        iterator = <generator object BaseSearchCV._fit.<locals>.<genexpr>>\n    780                 self._iterating = True\n    781             else:\n    782                 self._iterating = False\n    783 \n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=4), iterator=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    620             tasks = BatchedCalls(itertools.islice(iterator, batch_size))\n    621             if len(tasks) == 0:\n    622                 # No more tasks available in the iterator: tell caller to stop.\n    623                 return False\n    624             else:\n--> 625                 self._dispatch(tasks)\n        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=4)>\n        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    626                 return True\n    627 \n    628     def _print(self, msg, msg_args):\n    629         \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=4), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    583         self.n_dispatched_tasks += len(batch)\n    584         self.n_dispatched_batches += 1\n    585 \n    586         dispatch_timestamp = time.time()\n    587         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)\n--> 588         job = self._backend.apply_async(batch, callback=cb)\n        job = undefined\n        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>\n    589         self._jobs.append(job)\n    590 \n    591     def dispatch_next(self):\n    592         \"\"\"Dispatch more data for parallel processing\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)\n    106             raise ValueError('n_jobs == 0 in Parallel has no meaning')\n    107         return 1\n    108 \n    109     def apply_async(self, func, callback=None):\n    110         \"\"\"Schedule a func to be run\"\"\"\n--> 111         result = ImmediateResult(func)\n        result = undefined\n        func = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    112         if callback:\n    113             callback(result)\n    114         return result\n    115 \n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    327 \n    328 class ImmediateResult(object):\n    329     def __init__(self, batch):\n    330         # Don't delay the application, to avoid keeping the input\n    331         # arguments in memory\n--> 332         self.results = batch()\n        self.results = undefined\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    333 \n    334     def get(self):\n    335         return self.results\n    336 \n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (GradientBoostingRegressor(alpha=0.9, criterion='...      subsample=1.0, verbose=0, warm_start=False), array([[4.480e+02, 2.000e+00, 6.000e+01, ..., 0...., ..., 0.000e+00, 0.000e+00,\n        0.000e+00]]), array([2.33, 2.67, 1.  , 1.33, 2.67, 1.  , 2.  ,...1.33, 2.33, 2.75, 1.67, 1.25, 1.67,\n       2.33]), <function _passthrough_scorer>, array([ 134, 1492,  891, ..., 1777,  323, 1307]), array([1054,  714, 1056,  342, 1085,  782,   17,... 774, 1539, 1057,  282,\n       1494, 1031,  525]), 0, {'learning_rate': 0.05, 'max_depth': 9, 'max_features': 0.3, 'min_samples_leaf': 18, 'n_estimators': 25}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (GradientBoostingRegressor(alpha=0.9, criterion='...      subsample=1.0, verbose=0, warm_start=False), array([[4.480e+02, 2.000e+00, 6.000e+01, ..., 0...., ..., 0.000e+00, 0.000e+00,\n        0.000e+00]]), array([2.33, 2.67, 1.  , 1.33, 2.67, 1.  , 2.  ,...1.33, 2.33, 2.75, 1.67, 1.25, 1.67,\n       2.33]), <function _passthrough_scorer>, array([ 134, 1492,  891, ..., 1777,  323, 1307]), array([1054,  714, 1056,  342, 1085,  782,   17,... 774, 1539, 1057,  282,\n       1494, 1031,  525]), 0, {'learning_rate': 0.05, 'max_depth': 9, 'max_features': 0.3, 'min_samples_leaf': 18, 'n_estimators': 25}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/cross_validation.py in _fit_and_score(estimator=GradientBoostingRegressor(alpha=0.9, criterion='...      subsample=1.0, verbose=0, warm_start=False), X=array([[4.480e+02, 2.000e+00, 6.000e+01, ..., 0...., ..., 0.000e+00, 0.000e+00,\n        0.000e+00]]), y=array([2.33, 2.67, 1.  , 1.33, 2.67, 1.  , 2.  ,...1.33, 2.33, 2.75, 1.67, 1.25, 1.67,\n       2.33]), scorer=<function _passthrough_scorer>, train=array([ 134, 1492,  891, ..., 1777,  323, 1307]), test=array([1054,  714, 1056,  342, 1085,  782,   17,... 774, 1539, 1057,  282,\n       1494, 1031,  525]), verbose=0, parameters={'learning_rate': 0.05, 'max_depth': 9, 'max_features': 0.3, 'min_samples_leaf': 18, 'n_estimators': 25}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1663     if parameters is not None:\n   1664         estimator.set_params(**parameters)\n   1665 \n   1666     start_time = time.time()\n   1667 \n-> 1668     X_train, y_train = _safe_split(estimator, X, y, train)\n        X_train = undefined\n        y_train = undefined\n        estimator = GradientBoostingRegressor(alpha=0.9, criterion='...      subsample=1.0, verbose=0, warm_start=False)\n        X = array([[4.480e+02, 2.000e+00, 6.000e+01, ..., 0...., ..., 0.000e+00, 0.000e+00,\n        0.000e+00]])\n        y = array([2.33, 2.67, 1.  , 1.33, 2.67, 1.  , 2.  ,...1.33, 2.33, 2.75, 1.67, 1.25, 1.67,\n       2.33])\n        train = array([ 134, 1492,  891, ..., 1777,  323, 1307])\n   1669     X_test, y_test = _safe_split(estimator, X, y, test, train)\n   1670 \n   1671     try:\n   1672         if y_train is None:\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/cross_validation.py in _safe_split(estimator=GradientBoostingRegressor(alpha=0.9, criterion='...      subsample=1.0, verbose=0, warm_start=False), X=array([[4.480e+02, 2.000e+00, 6.000e+01, ..., 0...., ..., 0.000e+00, 0.000e+00,\n        0.000e+00]]), y=array([2.33, 2.67, 1.  , 1.33, 2.67, 1.  , 2.  ,...1.33, 2.33, 2.75, 1.67, 1.25, 1.67,\n       2.33]), indices=array([ 134, 1492,  891, ..., 1777,  323, 1307]), train_indices=None)\n   1731             if train_indices is None:\n   1732                 X_subset = X[np.ix_(indices, indices)]\n   1733             else:\n   1734                 X_subset = X[np.ix_(indices, train_indices)]\n   1735         else:\n-> 1736             X_subset = safe_indexing(X, indices)\n        X_subset = undefined\n        X = array([[4.480e+02, 2.000e+00, 6.000e+01, ..., 0...., ..., 0.000e+00, 0.000e+00,\n        0.000e+00]])\n        indices = array([ 134, 1492,  891, ..., 1777,  323, 1307])\n   1737 \n   1738     if y is not None:\n   1739         y_subset = safe_indexing(y, indices)\n   1740     else:\n\n...........................................................................\n/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/utils/__init__.py in safe_indexing(X=array([[4.480e+02, 2.000e+00, 6.000e+01, ..., 0...., ..., 0.000e+00, 0.000e+00,\n        0.000e+00]]), indices=array([ 134, 1492,  891, ..., 1777,  323, 1307]))\n    155             return X.copy().iloc[indices]\n    156     elif hasattr(X, \"shape\"):\n    157         if hasattr(X, 'take') and (hasattr(indices, 'dtype') and\n    158                                    indices.dtype.kind == 'i'):\n    159             # This is often substantially faster than X[indices]\n--> 160             return X.take(indices, axis=0)\n        X.take = <built-in method take of numpy.ndarray object>\n        indices = array([ 134, 1492,  891, ..., 1777,  323, 1307])\n    161         else:\n    162             return X[indices]\n    163     else:\n    164         return [X[idx] for idx in indices]\n\nIndexError: index 1492 is out of bounds for size 155\n___________________________________________________________________________"
     ],
     "output_type": "error"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#OK we'll now call the plot_learning_curve module by feeding it the estimator (best estimator returned from GS) \n",
    "#and train/cv sets. \n",
    "#The module simply runs the estimator multiple times on subsets of the data provided and plots the train and cv scores. \n",
    "#Note that we're feeding the best parameters we've learned from GridSearchCV to the estimator now. \n",
    "#We may need to adjust the hyperparameters further if there is overfitting (or underfitting, though unlikely) \n",
    "\n",
    "logger.info('starting')\n",
    "title = \"Learning Curves (Gradient Boosted Regression Trees)\" \n",
    "gbr_estimator = GradientBoostingRegressor(n_estimators=best_est.n_estimators, \n",
    "                                      max_depth=best_est.max_depth, \n",
    "                                      learning_rate=best_est.learning_rate, \n",
    "                                      min_samples_leaf=best_est.min_samples_leaf, \n",
    "                                      max_features=best_est.max_features) \n",
    "plot_learning_curve(gbr_estimator, title, X, y, cv=cv, n_jobs=n_jobs) \n",
    "\n",
    "plt.show() \n",
    "logger.info('complete')\n",
    "\n",
    "#Looks like we've done a reasonable job getting about ~0.85 R-squared on the cv set and looks \n",
    "# from the learning curve that we may be able to do a bit better with more estimators. \n",
    "# Although we may need to reduce the learning rate even further to address any overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1940, 36)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1836, 36)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.74768437])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.ones([1,36])\n",
    "gbr_estimator.fit(X,y)\n",
    "gbr_estimator.predict(a)\n",
    "\n",
    "# l = [1,2,3,4,5,6,7,8,9,0,1,2,3,4,5,6,7,8,9,0,1,2,3,4,5,6,7,8,9,0,1,2,3,4,5,6]\n",
    "# gbr_estimator.predict(np.array(l).reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sellibrary.locations import FileLocations\n",
    "INTERMEDIATE_PATH = FileLocations.get_dropbox_intermediate_path()\n",
    "\n",
    "output_filename = INTERMEDIATE_PATH+'heavy_GradientBoostingRegressor.pickle'\n",
    "with open(output_filename, 'wb') as handle:\n",
    "    pickle.dump(gbr_estimator, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}