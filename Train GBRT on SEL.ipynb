{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dsluis/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/dsluis/anaconda3/lib/python3.6/site-packages/sklearn/learning_curve.py:22: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n",
      "/Users/dsluis/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import pickle\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import sys\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor \n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn import cross_validation \n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.datasets import load_digits \n",
    "from sklearn.learning_curve import learning_curve \n",
    "from sklearn.cross_validation import ShuffleSplit, train_test_split \n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sellibrary.gbrt import GBRTWrapper\n",
    "from sellibrary.text_file_loader import load_feature_matrix\n",
    "from sellibrary.filter_only_golden import FilterGolden\n",
    "from sellibrary.locations import FileLocations\n",
    "from sellibrary.wiki.wikipedia_datasets import WikipediaDataset\n",
    "from sellibrary.sel.dexter_dataset import DatasetDexter\n",
    "\n",
    "from sellibrary.util.test_train_splitter import DataSplitter\n",
    "\n",
    "INTERMEDIATE_PATH = FileLocations.get_dropbox_intermediate_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup logging\n",
    "\n",
    "\n",
    "handler = logging.StreamHandler()\n",
    "handler.setFormatter(logging.Formatter('%(asctime)s %(name)-12s %(levelname)-8s %(message)s'))\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.addHandler(handler)\n",
    "logger.propagate = False\n",
    "logger.setLevel(logging.INFO)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_r2_train_model(filename, number_features_per_line, feature_names):\n",
    "\n",
    "\n",
    "    X, y, docid_array, entity_id_array = load_feature_matrix(feature_filename=INTERMEDIATE_PATH + filename,\n",
    "                                                             feature_names=feature_names,\n",
    "                                                             entity_id_index=1,\n",
    "                                                             y_feature_index=2, \n",
    "                                                             first_feature_index=4, \n",
    "                                                             number_features_per_line=number_features_per_line,\n",
    "                                                             tmp_filename='/tmp/temp_conversion_file.txt'\n",
    "                                                             )\n",
    "    \n",
    "    # train only on records we have a golden salience for\n",
    "    fg = FilterGolden()\n",
    "    logger.info('X Shape = %s',X.shape)\n",
    "    logger.info('y Shape = %s',y.shape)\n",
    "    \n",
    "    dexter_dataset = DatasetDexter()\n",
    "    wikipedia_dataset = WikipediaDataset()\n",
    "\n",
    "    X2, y2, docid2, entityid2 = fg.get_only_golden_rows(X, y, docid_array, entity_id_array, dexter_dataset, wikipedia_dataset )\n",
    "\n",
    "#     X2, y2, docid2, entityid2 = fg.get_only_golden_rows(X, y, docid_array, entity_id_array)\n",
    "\n",
    "    \n",
    "    \n",
    "    wrapper = GBRTWrapper()\n",
    "    gbrt = wrapper.train_model_no_split(X2, y2,  n_estimators=40)\n",
    "    logger.info('trained')\n",
    "    #gbrt.save_model()\n",
    "\n",
    "    # from https://shankarmsy.github.io/stories/gbrt-sklearn.html\n",
    "    #One of the benefits of growing trees is that we can understand how important each of the features are \n",
    "    print (\"Feature Importances\" )\n",
    "    print (gbrt.feature_importances_) \n",
    "    print ()\n",
    "    #Let's print the R-squared value for train/test. This explains how much of the variance in the data our model is \n",
    "    #able to decipher. \n",
    "    print (\"R-squared for Train: %.2f\" %gbrt.score(X2, y2) )\n",
    "    #print (\"R-squared for Test: %.2f\" %gbrt.score(X_test, y_test) )\n",
    "    #- See more at: https://shankarmsy.github.io/stories/gbrt-sklearn.html#sthash.JNZQbnph.dpuf\n",
    "    return gbrt, X2, y2, docid2, entityid2\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#All right let's do this the right way. We'll use a cross-validation generator to \n",
    "# select train and CV datasets to finetune parameters such as C \n",
    "# (Regularization parameter we saw earlier). These hyperparameters are extremely critical to \n",
    "# the model. \n",
    "#Now, if we tune parameters against the Test dataset, we will end up biasing towards the test \n",
    "# set and will once again not generalize very well. We will also have no good way to find out \n",
    "# since we have essentially trained on all our data. \n",
    "#Luckily scikit-learn has builit-in packages that can help with this. We'll use a crossvalidation \n",
    "# generator that can train the model by tuning the parameters based on a cross-validation subset \n",
    "# (cv) that is picked from within the training set. A different cv subset will be picked for each iteration, we control the number of iterations. Then we will \n",
    "#use these cv/train splits and run a gridsearch function that will evaluate the model with each split and tune parameters \n",
    "#to give us the best parameter that gives the optimal result.\n",
    "\n",
    "#Defining this as a function so we can call it anytime we want\n",
    "\n",
    "\n",
    "\n",
    "def GradientBooster(param_grid, n_jobs, X, y, estimator):\n",
    "    \n",
    "    #Choose cross-validation generator - let's choose ShuffleSplit which randomly shuffles and selects Train and CV sets \n",
    "    #for each iteration. There are other methods like the KFold split.\n",
    "    cv = ShuffleSplit(X.shape[0], n_iter=10, test_size=0.2)\n",
    "    #Apply the cross-validation iterator on the Training set using GridSearchCV. This will run the classifier on the \n",
    "    #different train/cv splits using parameters specified and return the model that has the best results \n",
    "\n",
    "    # \n",
    "    #Note that we are tuning based on the F1 score 2PR/P+R where P is Precision and R is Recall. This may not always be \n",
    "    #the best score to tune our model on.  For now, we'll use F1.\n",
    "    classifier = GridSearchCV(estimator=estimator, cv=cv, param_grid=param_grid, n_jobs=n_jobs)\n",
    "    #Also note that we're feeding multiple neighbors to the GridSearch to try out. \n",
    "    #We'll now fit the training dataset to this classifier\n",
    "    classifier.fit(X, y)\n",
    "    #Let's look at the best estimator that was found by GridSearchCV\n",
    "    print (\"Best Estimator learned through GridSearch\")\n",
    "    print ( classifier.best_estimator_)\n",
    "    return cv, classifier.best_estimator_, classifier\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_num_jobs():\n",
    "    if sys.platform == 'win32':\n",
    "        return 8\n",
    "    else:\n",
    "        if sys.platform == 'linux': # Sherlock ML\n",
    "            return 8\n",
    "        else:\n",
    "            return 4 # mac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None, n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)): \n",
    "    \n",
    "    \"\"\" Generate a simple plot of the test and traning learning curve. \n",
    "    Parameters ---------- \n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods An object of that type which is cloned for each validation. \n",
    "    title : string Title for the chart. \n",
    "    X : array-like, shape (n_samples, n_features) Training vector, where n_samples is the number of samples and n_features is the number of features. \n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional Target relative to X for classification or regression; None for unsupervised learning. \n",
    "    ylim : tuple, shape (ymin, ymax), optional Defines minimum and maximum yvalues plotted. \n",
    "    cv : integer, cross-validation generator, optional If an integer is passed, it is the number of folds (defaults to 3). Specific cross-validation objects can be passed, see sklearn.cross_validation module for the list of possible objects \n",
    "    n_jobs : integer, optional Number of jobs to run in parallel (default 1). \"\"\" \n",
    "    fig = plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None: plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1,\n",
    "                     color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt, fig\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_info(best_est, X, y, tset):\n",
    "    print (\"--------------------------------\" )\n",
    "    print (tset+\" Best Estimator Parameters\" )\n",
    "    print (\"--------------------------------\" )\n",
    "    print (\"n_estimators: %d\" %best_est.n_estimators )\n",
    "    print (\"max_depth: %d\" %best_est.max_depth )\n",
    "    print (\"min_samples_leaf: %d\" %best_est.min_samples_leaf )\n",
    "    print (\"max_features: %.2f\" %best_est.max_features )\n",
    "    print (tset+\" R-squared: %.2f\" %best_est.score(X,y) )     \n",
    "    print (\"Learning Rate: %.2f\" %best_est.learning_rate )\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def perform_grid_search(X,y):\n",
    "\n",
    "    # if no space left on device, try setting the env ver JOBLIB_TEMP_FOLDER to /tmp\n",
    "    %env JOBLIB_TEMP_FOLDER=/tmp\n",
    "    #WARNING - THIS MIGHT TAKE A WHILE TO RUN. \n",
    "    # TRY ADJUSTING parameters such as n_jobs (jobs to run in parallel, before \n",
    "    #increasing this make sure your system can handle it), n_iter for ShuffleSplit \n",
    "    # (in the function definition) and reducing #number of values being tried for max_depth/n_estimators. \n",
    "    #SELECT INTERRUPT IN THE MENU AND PRESS INTERRUPT KERNEL IF YOU NEEDD TO STOP EXECUTION \n",
    "    logger.info('starting')\n",
    "\n",
    "    param_grid={'n_estimators':[450, 500, 550], # tried 250, 100, [50], 25\n",
    "                'learning_rate': [0.02, 0.01, 0.005],# tried 0.2, 0.1, [0.05], 0.02, 0.01],\n",
    "                'max_depth':[7, 9, 12], # tried 6,[9],12\n",
    "                'min_samples_leaf':[18, 20, 22], # tried  2,5,9,12,15,[18]\n",
    "                'max_features':[0.2,0.3,0.4] # tried 0.2,[0.3],0.4,0.5\n",
    "               } \n",
    "    n_jobs = get_num_jobs() \n",
    "\n",
    "    #Let's fit GBRT to the digits training dataset by calling the function we just created. \n",
    "    estimator = GradientBoostingRegressor()\n",
    "\n",
    "    cv, best_est, trained_model=GradientBooster(param_grid, n_jobs, X, y, estimator) \n",
    "    logger.info('complete')\n",
    "    print_info(best_est, X, y, '.8CV')\n",
    "    \n",
    "    return cv, best_est\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-23 09:43:53,137 sellibrary.text_file_loader INFO     loading data from : /Users/dsluis/Dropbox/Datasets/intermediate/aws/all.txt\n",
      "2018-07-23 09:43:54,108 sellibrary.text_file_loader INFO     10000 lines processed\n",
      "2018-07-23 09:43:54,177 sellibrary.text_file_loader INFO     20000 lines processed\n",
      "2018-07-23 09:43:54,295 sellibrary.text_file_loader INFO     30000 lines processed\n",
      "2018-07-23 09:43:54,354 sellibrary.text_file_loader INFO     40000 lines processed\n",
      "2018-07-23 09:43:54,415 sellibrary.text_file_loader INFO     50000 lines processed\n",
      "2018-07-23 09:43:54,469 sellibrary.text_file_loader INFO     60000 lines processed\n",
      "2018-07-23 09:43:54,472 sellibrary.text_file_loader INFO     skipping line with 125 rather than 63 fields \"26,716712,0,0,[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 741, 2.0, 2, 0, 1.0539811066126856, 2.1079622132253713, 2.0, 0.5, 1, 633, 2.0, 2, 0, 1.0442338072669826, 2.088467614533965, 2.0, 0.5, 1, 0, 0, 0, nan, nan, nan, 0, 0, 0, 0, 0, 0, nan, nan, nan, 0, 0, 0]101,1189896,0,0,[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 383, 2.0, 1, 0, 1.0365535248041775, 2.073107049608355, 7.0, 0.14285714285714285, 1, 289, 2.0, 1, 0, 1.0173010380622838, 2.0346020761245676, 7.0, 0.14285714285714285, 1, 0, 0, 0, nan, nan, nan, 0, 0, 0, 0, 0, 0, nan, nan, nan, 0, 0, 0]\"\n",
      "2018-07-23 09:43:54,525 sellibrary.text_file_loader INFO     70000 lines processed\n",
      "2018-07-23 09:43:54,582 sellibrary.text_file_loader INFO     80000 lines processed\n",
      "2018-07-23 09:43:54,632 sellibrary.text_file_loader INFO     90000 lines processed\n",
      "2018-07-23 09:43:54,686 sellibrary.text_file_loader INFO     100000 lines processed\n",
      "2018-07-23 09:43:54,741 sellibrary.text_file_loader INFO     110000 lines processed\n",
      "2018-07-23 09:43:54,793 sellibrary.text_file_loader INFO     120000 lines processed\n",
      "2018-07-23 09:43:54,853 sellibrary.text_file_loader INFO     130000 lines processed\n",
      "2018-07-23 09:43:54,910 sellibrary.text_file_loader INFO     140000 lines processed\n",
      "2018-07-23 09:43:54,962 sellibrary.text_file_loader INFO     150000 lines processed\n",
      "2018-07-23 09:43:55,019 sellibrary.text_file_loader INFO     160000 lines processed\n",
      "2018-07-23 09:43:55,075 sellibrary.text_file_loader INFO     170000 lines processed\n",
      "2018-07-23 09:43:55,127 sellibrary.text_file_loader INFO     180000 lines processed\n",
      "2018-07-23 09:43:55,184 sellibrary.text_file_loader INFO     190000 lines processed\n",
      "2018-07-23 09:43:55,237 sellibrary.text_file_loader INFO     200000 lines processed\n",
      "2018-07-23 09:43:55,292 sellibrary.text_file_loader INFO     210000 lines processed\n",
      "2018-07-23 09:43:55,346 sellibrary.text_file_loader INFO     220000 lines processed\n",
      "2018-07-23 09:43:55,398 sellibrary.text_file_loader INFO     230000 lines processed\n",
      "2018-07-23 09:43:55,471 sellibrary.text_file_loader INFO     240000 lines processed\n",
      "2018-07-23 09:43:55,549 sellibrary.text_file_loader INFO     250000 lines processed\n",
      "2018-07-23 09:43:55,624 sellibrary.text_file_loader INFO     260000 lines processed\n",
      "2018-07-23 09:43:55,690 sellibrary.text_file_loader INFO     270000 lines processed\n",
      "2018-07-23 09:43:55,766 sellibrary.text_file_loader INFO     280000 lines processed\n",
      "2018-07-23 09:43:55,835 sellibrary.text_file_loader INFO     290000 lines processed\n",
      "2018-07-23 09:43:55,900 sellibrary.text_file_loader INFO     300000 lines processed\n",
      "2018-07-23 09:43:55,967 sellibrary.text_file_loader INFO     310000 lines processed\n",
      "2018-07-23 09:43:56,035 sellibrary.text_file_loader INFO     320000 lines processed\n",
      "2018-07-23 09:43:56,114 sellibrary.text_file_loader INFO     330000 lines processed\n",
      "2018-07-23 09:43:56,198 sellibrary.text_file_loader INFO     340000 lines processed\n",
      "2018-07-23 09:43:56,269 sellibrary.text_file_loader INFO     350000 lines processed\n",
      "2018-07-23 09:43:56,333 sellibrary.text_file_loader INFO     360000 lines processed\n",
      "2018-07-23 09:43:56,400 sellibrary.text_file_loader INFO     370000 lines processed\n",
      "2018-07-23 09:43:56,458 sellibrary.text_file_loader INFO     380000 lines processed\n",
      "2018-07-23 09:43:56,512 sellibrary.text_file_loader INFO     390000 lines processed\n",
      "2018-07-23 09:43:56,568 sellibrary.text_file_loader INFO     400000 lines processed\n",
      "2018-07-23 09:43:56,618 sellibrary.text_file_loader INFO     410000 lines processed\n",
      "2018-07-23 09:43:56,671 sellibrary.text_file_loader INFO     420000 lines processed\n",
      "2018-07-23 09:43:56,723 sellibrary.text_file_loader INFO     430000 lines processed\n",
      "2018-07-23 09:43:56,779 sellibrary.text_file_loader INFO     440000 lines processed\n",
      "2018-07-23 09:43:56,838 sellibrary.text_file_loader INFO     450000 lines processed\n",
      "2018-07-23 09:43:56,891 sellibrary.text_file_loader INFO     460000 lines processed\n",
      "2018-07-23 09:43:56,967 sellibrary.text_file_loader INFO     470000 lines processed\n",
      "2018-07-23 09:43:57,047 sellibrary.text_file_loader INFO     480000 lines processed\n",
      "2018-07-23 09:43:57,125 sellibrary.text_file_loader INFO     490000 lines processed\n",
      "2018-07-23 09:43:57,191 sellibrary.text_file_loader INFO     500000 lines processed\n",
      "2018-07-23 09:43:57,266 sellibrary.text_file_loader INFO     510000 lines processed\n",
      "2018-07-23 09:43:57,340 sellibrary.text_file_loader INFO     520000 lines processed\n",
      "2018-07-23 09:43:57,413 sellibrary.text_file_loader INFO     530000 lines processed\n",
      "2018-07-23 09:43:57,482 sellibrary.text_file_loader INFO     540000 lines processed\n",
      "2018-07-23 09:43:57,557 sellibrary.text_file_loader INFO     550000 lines processed\n",
      "2018-07-23 09:43:57,625 sellibrary.text_file_loader INFO     560000 lines processed\n",
      "2018-07-23 09:43:57,686 sellibrary.text_file_loader INFO     570000 lines processed\n",
      "2018-07-23 09:43:57,742 sellibrary.text_file_loader INFO     580000 lines processed\n",
      "2018-07-23 09:43:57,795 sellibrary.text_file_loader INFO     590000 lines processed\n",
      "2018-07-23 09:43:57,848 sellibrary.text_file_loader INFO     600000 lines processed\n",
      "2018-07-23 09:43:57,900 sellibrary.text_file_loader INFO     610000 lines processed\n",
      "2018-07-23 09:43:57,953 sellibrary.text_file_loader INFO     620000 lines processed\n",
      "2018-07-23 09:43:58,004 sellibrary.text_file_loader INFO     630000 lines processed\n",
      "2018-07-23 09:43:58,061 sellibrary.text_file_loader INFO     640000 lines processed\n",
      "2018-07-23 09:43:58,087 sellibrary.text_file_loader INFO     643790 lines loaded from /Users/dsluis/Dropbox/Datasets/intermediate/aws/all.txt\n",
      "2018-07-23 09:44:57,694 sellibrary.wiki.wikipedia_datasets INFO     Loading /Users/dsluis/Dropbox/Datasets/wikipedia/wikititle_id_by_id.case_insensitive.15910478.pickle\n",
      "2018-07-23 09:45:18,004 sellibrary.wiki.wikipedia_datasets INFO     Loaded /Users/dsluis/Dropbox/Datasets/wikipedia/wikititle_id_by_id.case_insensitive.15910478.pickle\n",
      "2018-07-23 09:45:19,185 __main__     INFO     After filtering only golden rows:\n",
      "2018-07-23 09:45:19,186 __main__     INFO     X Shape = (3865, 59)\n",
      "2018-07-23 09:45:19,187 __main__     INFO     y Shape = (3865,)\n"
     ]
    }
   ],
   "source": [
    "light_feature_names = [\n",
    "    'min_normalised_position',  # 1\n",
    "    'max_normalised_position',  # 1\n",
    "    'mean_normalised_position',  # 1\n",
    "    'normalised_position_std_dev',  # 1\n",
    "    'norm_first_position_within_first 3 sentences',  # 2\n",
    "    'norm first positon within body middle',  # 2\n",
    "    'norm_first_position_within last 3 sentences',  # 2\n",
    "    'normed first position within title',  # 2\n",
    "    'averaged normed position within sentences',  # 3\n",
    "    'freq in first 3 sentences of body ',  # 4\n",
    "    'freq in middle of body ',  # 4\n",
    "    'freq in last 3 sentences of body ',  # 4\n",
    "    'freq in title ',  # 4\n",
    "    'one occurrence capitalised',  # 5\n",
    "    'maximum fraction of uppercase letters',  # 6\n",
    "    'average spot length in words',  # 8.1 :\n",
    "    'average spot length in characters',  # 8.2 :\n",
    "    'is in title',  # 11 :\n",
    "    'unambiguous entity frequency',  # 14 : 1 entity frequency feature\n",
    "    'entity in_degree in wikipeada',  # 20 :\n",
    "    'entity out_degree in wikipeada',  # 20 :\n",
    "    'entity degree in wikipeada',  # 20 :\n",
    "    'document length',  # 22 :\n",
    "]\n",
    "\n",
    "heavy_feature_names = [\n",
    "    'v1_graph_size', 'v1_graph_diameter', 'v1_node_degree', 'v1_degree_mean_median_ratio',\n",
    "    'v1_out_degree_mean_median_ratio', 'v1_degree_mean_median_ratio', 'v1_farness', 'v1_closeness', 'v1_centrality',\n",
    "    'v1_minus_low_relatedness_graph_size', 'v1_minus_low_relatedness_graph_diameter',\n",
    "    'v1_minus_low_relatedness_node_degree', 'v1_minus_low_relatedness_degree_mean_median_ratio',\n",
    "    'v1_minus_low_relatedness_out_degree_mean_median_ratio', 'v1_minus_low_relatedness_degree_mean_median_ratio',\n",
    "    'v1_minus_low_relatedness_farness', 'v1_minus_low_relatedness_closeness',\n",
    "    'v1_minus_low_relatedness_centrality', 'v0_graph_size', 'v0_graph_diameter', 'v0_node_degree',\n",
    "    'v0_degree_mean_median_ratio', 'v0_out_degree_mean_median_ratio', 'v0_degree_mean_median_ratio', 'v0_farness',\n",
    "    'v0_closeness', 'v0_centrality', 'v0_minus_low_relatedness_graph_size',\n",
    "    'v0_minus_low_relatedness_graph_diameter', 'v0_minus_low_relatedness_node_degree',\n",
    "    'v0_minus_low_relatedness_degree_mean_median_ratio', 'v0_minus_low_relatedness_out_degree_mean_median_ratio',\n",
    "    'v0_minus_low_relatedness_degree_mean_median_ratio', 'v0_minus_low_relatedness_farness',\n",
    "    'v0_minus_low_relatedness_closeness', 'v0_minus_low_relatedness_centrality'\n",
    "]\n",
    "\n",
    "all_feature_names = light_feature_names\n",
    "all_feature_names.extend(heavy_feature_names)\n",
    "\n",
    "X_sel, y_sel, docid_array_sel, entity_id_array_sel = load_feature_matrix(\n",
    "    feature_filename=INTERMEDIATE_PATH+'aws/all.txt',\n",
    "    feature_names=all_feature_names,\n",
    "    entity_id_index=1,\n",
    "    y_feature_index=2, first_feature_index=4, number_features_per_line=len(all_feature_names) + 4,\n",
    "    tmp_filename='/tmp/temp_conversion_file.txt'\n",
    "    )\n",
    "\n",
    "# remove any rows that are not in the golden set\n",
    "dexterDataset = DatasetDexter()\n",
    "wikipediaDataset = WikipediaDataset()\n",
    "fg = FilterGolden()\n",
    "X_sel, y_sel, docid_array_sel, entity_id_array_sel = fg.get_only_golden_rows(X_sel, y_sel, docid_array_sel, entity_id_array_sel, dexterDataset, wikipediaDataset)\n",
    "logger.info('After filtering only golden rows:')\n",
    "logger.info('X Shape = %s', X_sel.shape)\n",
    "logger.info('y Shape = %s', y_sel.shape)\n",
    "\n",
    "# set sentiment to a binary classifier\n",
    "# y_sel[y_sel < 2.0] = 0\n",
    "# y_sel [y_sel >= 2.0] = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save data to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "output_filename = INTERMEDIATE_PATH+'SEL_dataset.pickle'\n",
    "sel_dict = {\"X\":X_sel, \"y\":y_sel, \"docid\": docid_array_sel, \"entity_id\": entity_id_array_sel}\n",
    "with open(output_filename, 'wb') as handle:\n",
    "     pickle.dump(sel_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# import os\n",
    "# input_filename =  INTERMEDIATE_PATH + 'SEL_dataset.pickle'\n",
    "# if os.path.isfile(input_filename):\n",
    "#     logger.info('loading data from %s', input_filename)\n",
    "#     with open(input_filename, 'rb') as handle:\n",
    "#         sel_dict = pickle.load(handle)      \n",
    "#         X_sel = sel_dict[\"X\"]\n",
    "#         y_sel = sel_dict[\"y\"]\n",
    "#         docid_array_sel = sel_dict[\"docid\"]\n",
    "#         entity_id_array_sel = sel_dict[\"entity_id\"]\n",
    "        \n",
    "#     logger.info('loaded')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Grid Search for Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-21 18:12:21,831 __main__     INFO     starting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: JOBLIB_TEMP_FOLDER=/tmp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-21 18:33:25,649 __main__     INFO     complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator learned through GridSearch\n",
      "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "             learning_rate=0.01, loss='ls', max_depth=7, max_features=0.2,\n",
      "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "             min_impurity_split=None, min_samples_leaf=22,\n",
      "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "             n_estimators=500, presort='auto', random_state=None,\n",
      "             subsample=1.0, verbose=0, warm_start=False)\n",
      "--------------------------------\n",
      ".8CV Best Estimator Parameters\n",
      "--------------------------------\n",
      "n_estimators: 500\n",
      "max_depth: 7\n",
      "min_samples_leaf: 22\n",
      "max_features: 0.20\n",
      ".8CV R-squared: 0.79\n",
      "Learning Rate: 0.01\n"
     ]
    }
   ],
   "source": [
    "cv, best_est = perform_grid_search(X_sel,y_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "# Plot Learning Curve - How much data we need\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-23 10:48:17,402 __main__     INFO     starting\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10cc24748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-23 10:48:44,748 __main__     INFO     complete\n"
     ]
    }
   ],
   "source": [
    "#OK we'll now call the plot_learning_curve module by feeding it the estimator (best estimator returned from GS) \n",
    "#and train/cv sets. \n",
    "#The module simply runs the estimator multiple times on subsets of the data provided and plots the train and cv scores. \n",
    "#Note that we're feeding the best parameters we've learned from GridSearchCV to the estimator now. \n",
    "#We may need to adjust the hyperparameters further if there is overfitting (or underfitting, though unlikely) \n",
    "\n",
    "logger.info('starting')\n",
    "title = \"Learning Curves (Gradient Boosted Regression Trees)\" \n",
    "n_jobs = get_num_jobs()\n",
    "gbr_estimator = GradientBoostingRegressor(n_estimators=best_est.n_estimators, \n",
    "                                      max_depth=best_est.max_depth, \n",
    "                                      learning_rate=best_est.learning_rate, \n",
    "                                      min_samples_leaf=best_est.min_samples_leaf, \n",
    "                                      max_features=best_est.max_features) \n",
    "plt, fig = plot_learning_curve(gbr_estimator, title, X_sel, y_sel, cv=cv, n_jobs=n_jobs) \n",
    "\n",
    "plt.show() \n",
    "GRAPH_PATH = '/Users/dsluis/Dropbox/UCL/UCL - Business Analytics specialisation in Computer Science/T3-COMPG099 - Dissertation/Diagrams/'\n",
    "fig.savefig(GRAPH_PATH+'Learning_curve_GBRT.png')\n",
    "logger.info('complete')\n",
    "\n",
    "# R-squared revers to the proportion of variation in data that can be explained by our model. \n",
    "# 1.0 is perfect, 0.05 not very useful\n",
    "# Distance between train and cross validation = \n",
    "# Gradient suggest whether more training data is useful\n",
    "# How does the number of estimators affect the curve?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data - to train real model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "splitter = DataSplitter()\n",
    "X_train, X_test, y_train, y_test, in_train_set_by_id = splitter.get_test_train_datasets(X_sel,y_sel,docid_array_sel,7,train_split=0.50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2004, 59)\n",
      "(1861, 59)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset\n",
      "1,2,4,6,7,9,10,11,12,13,16,17,22,24,26,27,28,29,31,34,36,37,38,40,41,43,44,49,54,56,57,60,62,63,71,75,78,81,86,87,89,90,91,93,94,96,98,99,101,103,108,109,110,113,114,115,116,118,123,124,125,126,136,141,144,145,148,149,150,151,153,154,155,156,157,158,159,162,163,165,166,167,170,171,172,173,174,175,178,180,183,185,190,191,192,196,197,205,207,208,209,210,211,214,218,219,221,222,223,227,230,236,237,239,243,244,247,248,249,252,256,258,259,264,267,268,269,270,272,273,274,276,277,280,285,288,290,291,293,294,298,302,304,305,313,318,320,326,331,332,333,334,336,337,341,532,538,541,542,546,548,551,553,555,561,566,567,568,571,575,576,577,579,580,582,587,588,593,594,596,597,601,603\n",
      "Length:183\n",
      "Testset\n",
      "3,5,8,14,18,20,21,23,25,30,32,33,35,39,42,45,46,50,51,52,53,55,58,64,66,68,70,72,73,74,76,77,80,82,83,84,85,88,95,100,104,105,106,107,111,112,119,127,129,131,132,133,134,137,138,139,140,146,160,161,168,169,177,181,182,184,186,187,188,189,193,194,195,198,199,200,202,203,204,206,212,213,215,216,217,224,225,226,228,229,232,233,234,235,238,241,242,245,246,250,251,253,254,255,257,260,261,262,263,265,266,271,275,278,279,281,282,283,284,292,295,296,299,300,301,303,306,307,308,311,312,314,315,316,317,319,321,323,324,325,327,329,330,338,339,340,528,530,534,536,540,543,545,550,560,562,569,570,572,573,574,578,583,586,589,590,591,595,598,599,600,602,604\n",
      "Length:173\n"
     ]
    }
   ],
   "source": [
    "in_train_set_by_id\n",
    "\n",
    "ids_in_trainset = []\n",
    "ids_in_testset = []\n",
    "for i in in_train_set_by_id.keys():\n",
    "    if in_train_set_by_id[i]:\n",
    "        ids_in_trainset.append(int(i))\n",
    "    else:\n",
    "        ids_in_testset.append(int(i))\n",
    "        \n",
    "len(ids_in_trainset)\n",
    "s = str(ids_in_trainset)\n",
    "s = s.replace(' ','').replace('[','').replace(']','')\n",
    "print('Trainset\\n'+s)\n",
    "print('Length:'+str(len(ids_in_trainset)))\n",
    "\n",
    "\n",
    "len(ids_in_testset)\n",
    "s = str(ids_in_testset)\n",
    "s = s.replace(' ','').replace('[','').replace(']','')\n",
    "print('Testset\\n'+s)\n",
    "print('Length:'+str(len(ids_in_testset)))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances\n",
      "[ 0.09410583  0.03896216  0.0410011   0.02237894  0.04104831  0.01982013\n",
      "  0.00641015  0.02739751  0.03144776  0.03964829  0.00941675  0.00189437\n",
      "  0.08160791  0.          0.02248566  0.01130819  0.03256522  0.\n",
      "  0.02331491  0.01177357  0.01985515  0.02128245  0.05215933  0.03440074\n",
      "  0.00394308  0.01905097  0.01352031  0.01539162  0.02348947  0.02979972\n",
      "  0.02648647  0.          0.02984903  0.0022995   0.02069068  0.01043718\n",
      "  0.0174978   0.02613859  0.01872812  0.02164845  0.          0.00343221\n",
      "  0.00135549  0.00235792  0.00155545  0.00333118  0.00571725  0.00200692\n",
      "  0.00297599  0.00186071  0.00320891  0.00064341  0.00033096  0.00046638\n",
      "  0.00246532  0.00395372  0.00027906  0.00063104  0.00017266]\n",
      "\n",
      "R-squared for Train: 0.53\n"
     ]
    }
   ],
   "source": [
    "gbr_estimator.fit(X_train,y_train)\n",
    "print (\"Feature Importances\" )\n",
    "print (gbr_estimator.feature_importances_) \n",
    "print ()\n",
    "#Let's print the R-squared value for train/test. This explains how much of the variance in the data our model is \n",
    "#able to decipher. \n",
    "print (\"R-squared for Train: %.2f\" %gbr_estimator.score(X_test, y_test) )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6497055073108036"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "a = np.ones([1,59])\n",
    "gbr_estimator.predict(a)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_filename = INTERMEDIATE_PATH+'sel_golden_spotter_GradientBoostingRegressor.pickle'\n",
    "with open(output_filename, 'wb') as handle:\n",
    "     pickle.dump(gbr_estimator, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.01, loss='ls', max_depth=7, max_features=0.2,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=22,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=500, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
